{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w2hrA8Gnpqo"
      },
      "source": [
        "# Importação de bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nXNwb6hnsuX",
        "outputId": "2d8f93e2-bb58-4555-b795-b6cf8667a4b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
            "scipy 1.6.2 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.24.4 which is incompatible.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (1.2.4)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.0.3-cp38-cp38-win_amd64.whl (10.8 MB)\n",
            "Collecting numpy>=1.20.3\n",
            "  Downloading numpy-1.24.4-cp38-cp38-win_amd64.whl (14.9 MB)\n",
            "Collecting python-dateutil>=2.8.2\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2021.1)\n",
            "Collecting tzdata>=2022.1\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
            "Installing collected packages: tzdata, python-dateutil, numpy, pandas\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.1\n",
            "    Uninstalling python-dateutil-2.8.1:\n",
            "      Successfully uninstalled python-dateutil-2.8.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.20.1\n",
            "    Uninstalling numpy-1.20.1:\n",
            "      Successfully uninstalled numpy-1.20.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.2.4\n",
            "    Uninstalling pandas-1.2.4:\n",
            "      Successfully uninstalled pandas-1.2.4\n",
            "Successfully installed numpy-1.24.4 pandas-2.0.3 python-dateutil-2.9.0.post0 tzdata-2025.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas --upgrade\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gE1iFNwjg5M"
      },
      "source": [
        "## Importação do dataset (walmart-recruiting-store-sales-forecasting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-_3IZ4aPgfHk",
        "outputId": "55ba9edf-1030-401d-b28a-074b71968d7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arquivo features.csv importado como dataframe 'features' do GitHub.\n",
            "Arquivo sampleSubmission.csv importado como dataframe 'sampleSubmission' do GitHub.\n",
            "Arquivo stores.csv importado como dataframe 'stores' do GitHub.\n",
            "Arquivo test.csv importado como dataframe 'test' do GitHub.\n",
            "Arquivo train.csv importado como dataframe 'train' do GitHub.\n",
            "\n",
            "Exibindo as 5 primeiras linhas de cada dataframe:\n",
            "\n",
            "Exibindo dataframe 'df_stores':\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Store",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Type",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Size",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "e1802e04-8316-46d7-bf6b-794d6434a72a",
              "rows": [
                [
                  "0",
                  "1",
                  "A",
                  "151315"
                ],
                [
                  "1",
                  "2",
                  "A",
                  "202307"
                ],
                [
                  "2",
                  "3",
                  "B",
                  "37392"
                ],
                [
                  "3",
                  "4",
                  "A",
                  "205863"
                ],
                [
                  "4",
                  "5",
                  "B",
                  "34875"
                ]
              ],
              "shape": {
                "columns": 3,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Type</th>\n",
              "      <th>Size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>151315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>A</td>\n",
              "      <td>202307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B</td>\n",
              "      <td>37392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>A</td>\n",
              "      <td>205863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B</td>\n",
              "      <td>34875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Store Type    Size\n",
              "0      1    A  151315\n",
              "1      2    A  202307\n",
              "2      3    B   37392\n",
              "3      4    A  205863\n",
              "4      5    B   34875"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Exibindo dataframe 'df_train':\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Store",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Dept",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Date",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Weekly_Sales",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "IsHoliday",
                  "rawType": "bool",
                  "type": "boolean"
                }
              ],
              "ref": "819ee244-db45-45de-803a-5d5835ec39d4",
              "rows": [
                [
                  "0",
                  "1",
                  "1",
                  "2010-02-05",
                  "24924.5",
                  "False"
                ],
                [
                  "1",
                  "1",
                  "1",
                  "2010-02-12",
                  "46039.49",
                  "True"
                ],
                [
                  "2",
                  "1",
                  "1",
                  "2010-02-19",
                  "41595.55",
                  "False"
                ],
                [
                  "3",
                  "1",
                  "1",
                  "2010-02-26",
                  "19403.54",
                  "False"
                ],
                [
                  "4",
                  "1",
                  "1",
                  "2010-03-05",
                  "21827.9",
                  "False"
                ]
              ],
              "shape": {
                "columns": 5,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Dept</th>\n",
              "      <th>Date</th>\n",
              "      <th>Weekly_Sales</th>\n",
              "      <th>IsHoliday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>24924.50</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-12</td>\n",
              "      <td>46039.49</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-19</td>\n",
              "      <td>41595.55</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-26</td>\n",
              "      <td>19403.54</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-03-05</td>\n",
              "      <td>21827.90</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Store  Dept        Date  Weekly_Sales  IsHoliday\n",
              "0      1     1  2010-02-05      24924.50      False\n",
              "1      1     1  2010-02-12      46039.49       True\n",
              "2      1     1  2010-02-19      41595.55      False\n",
              "3      1     1  2010-02-26      19403.54      False\n",
              "4      1     1  2010-03-05      21827.90      False"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Exibindo dataframe 'df_test':\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Store",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Dept",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Date",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "IsHoliday",
                  "rawType": "bool",
                  "type": "boolean"
                }
              ],
              "ref": "a915e398-7f83-4f3f-a27d-c6c1f0252c20",
              "rows": [
                [
                  "0",
                  "1",
                  "1",
                  "2012-11-02",
                  "False"
                ],
                [
                  "1",
                  "1",
                  "1",
                  "2012-11-09",
                  "False"
                ],
                [
                  "2",
                  "1",
                  "1",
                  "2012-11-16",
                  "False"
                ],
                [
                  "3",
                  "1",
                  "1",
                  "2012-11-23",
                  "True"
                ],
                [
                  "4",
                  "1",
                  "1",
                  "2012-11-30",
                  "False"
                ]
              ],
              "shape": {
                "columns": 4,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Dept</th>\n",
              "      <th>Date</th>\n",
              "      <th>IsHoliday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2012-11-02</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2012-11-09</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2012-11-16</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2012-11-23</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2012-11-30</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Store  Dept        Date  IsHoliday\n",
              "0      1     1  2012-11-02      False\n",
              "1      1     1  2012-11-09      False\n",
              "2      1     1  2012-11-16      False\n",
              "3      1     1  2012-11-23       True\n",
              "4      1     1  2012-11-30      False"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Exibindo dataframe 'df_sampleSubmission':\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Id",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Weekly_Sales",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "40449768-3905-4e33-94d5-3107a0949c6d",
              "rows": [
                [
                  "0",
                  "1_1_2012-11-02",
                  "0"
                ],
                [
                  "1",
                  "1_1_2012-11-09",
                  "0"
                ],
                [
                  "2",
                  "1_1_2012-11-16",
                  "0"
                ],
                [
                  "3",
                  "1_1_2012-11-23",
                  "0"
                ],
                [
                  "4",
                  "1_1_2012-11-30",
                  "0"
                ]
              ],
              "shape": {
                "columns": 2,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Weekly_Sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1_1_2012-11-02</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1_1_2012-11-09</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1_1_2012-11-16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1_1_2012-11-23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1_1_2012-11-30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Id  Weekly_Sales\n",
              "0  1_1_2012-11-02             0\n",
              "1  1_1_2012-11-09             0\n",
              "2  1_1_2012-11-16             0\n",
              "3  1_1_2012-11-23             0\n",
              "4  1_1_2012-11-30             0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Exibindo dataframe 'df_features':\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Store",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Date",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Temperature",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_Price",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown2",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown3",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown4",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown5",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "CPI",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Unemployment",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "IsHoliday",
                  "rawType": "bool",
                  "type": "boolean"
                }
              ],
              "ref": "5f67fc73-ada0-4094-877e-72855f0f56d4",
              "rows": [
                [
                  "0",
                  "1",
                  "2010-02-05",
                  "42.31",
                  "2.572",
                  null,
                  null,
                  null,
                  null,
                  null,
                  "211.0963582",
                  "8.106",
                  "False"
                ],
                [
                  "1",
                  "1",
                  "2010-02-12",
                  "38.51",
                  "2.548",
                  null,
                  null,
                  null,
                  null,
                  null,
                  "211.2421698",
                  "8.106",
                  "True"
                ],
                [
                  "2",
                  "1",
                  "2010-02-19",
                  "39.93",
                  "2.514",
                  null,
                  null,
                  null,
                  null,
                  null,
                  "211.2891429",
                  "8.106",
                  "False"
                ],
                [
                  "3",
                  "1",
                  "2010-02-26",
                  "46.63",
                  "2.561",
                  null,
                  null,
                  null,
                  null,
                  null,
                  "211.3196429",
                  "8.106",
                  "False"
                ],
                [
                  "4",
                  "1",
                  "2010-03-05",
                  "46.5",
                  "2.625",
                  null,
                  null,
                  null,
                  null,
                  null,
                  "211.3501429",
                  "8.106",
                  "False"
                ]
              ],
              "shape": {
                "columns": 12,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Date</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Fuel_Price</th>\n",
              "      <th>MarkDown1</th>\n",
              "      <th>MarkDown2</th>\n",
              "      <th>MarkDown3</th>\n",
              "      <th>MarkDown4</th>\n",
              "      <th>MarkDown5</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Unemployment</th>\n",
              "      <th>IsHoliday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>42.31</td>\n",
              "      <td>2.572</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>211.096358</td>\n",
              "      <td>8.106</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-12</td>\n",
              "      <td>38.51</td>\n",
              "      <td>2.548</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>211.242170</td>\n",
              "      <td>8.106</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-19</td>\n",
              "      <td>39.93</td>\n",
              "      <td>2.514</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>211.289143</td>\n",
              "      <td>8.106</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-26</td>\n",
              "      <td>46.63</td>\n",
              "      <td>2.561</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>211.319643</td>\n",
              "      <td>8.106</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2010-03-05</td>\n",
              "      <td>46.50</td>\n",
              "      <td>2.625</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>211.350143</td>\n",
              "      <td>8.106</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Store        Date  Temperature  Fuel_Price  MarkDown1  MarkDown2  \\\n",
              "0      1  2010-02-05        42.31       2.572        NaN        NaN   \n",
              "1      1  2010-02-12        38.51       2.548        NaN        NaN   \n",
              "2      1  2010-02-19        39.93       2.514        NaN        NaN   \n",
              "3      1  2010-02-26        46.63       2.561        NaN        NaN   \n",
              "4      1  2010-03-05        46.50       2.625        NaN        NaN   \n",
              "\n",
              "   MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment  IsHoliday  \n",
              "0        NaN        NaN        NaN  211.096358         8.106      False  \n",
              "1        NaN        NaN        NaN  211.242170         8.106       True  \n",
              "2        NaN        NaN        NaN  211.289143         8.106      False  \n",
              "3        NaN        NaN        NaN  211.319643         8.106      False  \n",
              "4        NaN        NaN        NaN  211.350143         8.106      False  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Definir o caminho base para os datasets raw no GitHub\n",
        "github_base_url = 'https://raw.githubusercontent.com/gustavolima007/demand-predictor-walmart-MLOps/main/data/walmart-recruiting-store-sales-forecasting/'\n",
        "\n",
        "# Lista para armazenar os dataframes\n",
        "dfs = {}\n",
        "\n",
        "# Nomes dos arquivos CSV a serem importados\n",
        "csv_files = [\n",
        "    'features.csv',\n",
        "    'sampleSubmission.csv',\n",
        "    'stores.csv',\n",
        "    'test.csv',\n",
        "    'train.csv'\n",
        "]\n",
        "\n",
        "# Importar cada arquivo CSV do GitHub\n",
        "for file_name in csv_files:\n",
        "    file_url = github_base_url + file_name\n",
        "    df_name = file_name.replace('.csv', '') # Nome do dataframe será o nome do arquivo sem a extensão\n",
        "    try:\n",
        "        dfs[df_name] = pd.read_csv(file_url)\n",
        "        print(f\"Arquivo {file_name} importado como dataframe '{df_name}' do GitHub.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao importar o arquivo {file_name} do GitHub: {e}\")\n",
        "\n",
        "# Agora, acesse e exiba as 5 primeiras linhas de cada dataframe\n",
        "print(\"\\nExibindo as 5 primeiras linhas de cada dataframe:\")\n",
        "\n",
        "# Acesse o dataframe 'stores' e exiba as 5 primeiras linhas\n",
        "df_stores = dfs.get('stores')\n",
        "if df_stores is not None:\n",
        "    print(\"\\nExibindo dataframe 'df_stores':\")\n",
        "    display(df_stores.head())\n",
        "\n",
        "# Acesse o dataframe 'train' e exiba as 5 primeiras linhas\n",
        "df_train = dfs.get('train')\n",
        "if df_train is not None:\n",
        "    print(\"\\nExibindo dataframe 'df_train':\")\n",
        "    display(df_train.head())\n",
        "\n",
        "# Acesse o dataframe 'test' e exiba as 5 primeiras linhas\n",
        "df_test = dfs.get('test')\n",
        "if df_test is not None:\n",
        "    print(\"\\nExibindo dataframe 'df_test':\")\n",
        "    display(df_test.head())\n",
        "\n",
        "# Acesse o dataframe 'sampleSubmission' e exiba as 5 primeiras linhas\n",
        "df_sampleSubmission = dfs.get('sampleSubmission')\n",
        "if df_sampleSubmission is not None:\n",
        "    print(\"\\nExibindo dataframe 'df_sampleSubmission':\")\n",
        "    display(df_sampleSubmission.head())\n",
        "\n",
        "# Acesse o dataframe 'features' e exiba as 5 primeiras linhas\n",
        "df_features = dfs.get('features')\n",
        "if df_features is not None:\n",
        "    print(\"\\nExibindo dataframe 'df_features':\")\n",
        "    display(df_features.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwCJb6i0jpZL"
      },
      "source": [
        "## Unificação dos Dados (Merge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "Gy1DS-_Zj6Lo",
        "outputId": "83066427-7f96-441e-af7d-0e36a26b338e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Exibindo as 5 primeiras linhas do dataframe df_train_merged:\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Store",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Dept",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Date",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Weekly_Sales",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "IsHoliday",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Type",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Size",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Temperature",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_Price",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown2",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown3",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown4",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown5",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "CPI",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Unemployment",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "3d489b11-5183-4a5d-8480-e90eacc449c8",
              "rows": [
                [
                  "0",
                  "1",
                  "1",
                  "2010-02-05",
                  "24924.5",
                  "False",
                  "A",
                  "151315",
                  "42.31",
                  "2.572",
                  null,
                  null,
                  null,
                  null,
                  null,
                  "211.0963582",
                  "8.106"
                ],
                [
                  "1",
                  "1",
                  "1",
                  "2010-02-12",
                  "46039.49",
                  "True",
                  "A",
                  "151315",
                  "38.51",
                  "2.548",
                  null,
                  null,
                  null,
                  null,
                  null,
                  "211.2421698",
                  "8.106"
                ],
                [
                  "2",
                  "1",
                  "1",
                  "2010-02-19",
                  "41595.55",
                  "False",
                  "A",
                  "151315",
                  "39.93",
                  "2.514",
                  null,
                  null,
                  null,
                  null,
                  null,
                  "211.2891429",
                  "8.106"
                ],
                [
                  "3",
                  "1",
                  "1",
                  "2010-02-26",
                  "19403.54",
                  "False",
                  "A",
                  "151315",
                  "46.63",
                  "2.561",
                  null,
                  null,
                  null,
                  null,
                  null,
                  "211.3196429",
                  "8.106"
                ],
                [
                  "4",
                  "1",
                  "1",
                  "2010-03-05",
                  "21827.9",
                  "False",
                  "A",
                  "151315",
                  "46.5",
                  "2.625",
                  null,
                  null,
                  null,
                  null,
                  null,
                  "211.3501429",
                  "8.106"
                ]
              ],
              "shape": {
                "columns": 16,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Dept</th>\n",
              "      <th>Date</th>\n",
              "      <th>Weekly_Sales</th>\n",
              "      <th>IsHoliday</th>\n",
              "      <th>Type</th>\n",
              "      <th>Size</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Fuel_Price</th>\n",
              "      <th>MarkDown1</th>\n",
              "      <th>MarkDown2</th>\n",
              "      <th>MarkDown3</th>\n",
              "      <th>MarkDown4</th>\n",
              "      <th>MarkDown5</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Unemployment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>24924.50</td>\n",
              "      <td>False</td>\n",
              "      <td>A</td>\n",
              "      <td>151315</td>\n",
              "      <td>42.31</td>\n",
              "      <td>2.572</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>211.096358</td>\n",
              "      <td>8.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-12</td>\n",
              "      <td>46039.49</td>\n",
              "      <td>True</td>\n",
              "      <td>A</td>\n",
              "      <td>151315</td>\n",
              "      <td>38.51</td>\n",
              "      <td>2.548</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>211.242170</td>\n",
              "      <td>8.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-19</td>\n",
              "      <td>41595.55</td>\n",
              "      <td>False</td>\n",
              "      <td>A</td>\n",
              "      <td>151315</td>\n",
              "      <td>39.93</td>\n",
              "      <td>2.514</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>211.289143</td>\n",
              "      <td>8.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-26</td>\n",
              "      <td>19403.54</td>\n",
              "      <td>False</td>\n",
              "      <td>A</td>\n",
              "      <td>151315</td>\n",
              "      <td>46.63</td>\n",
              "      <td>2.561</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>211.319643</td>\n",
              "      <td>8.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-03-05</td>\n",
              "      <td>21827.90</td>\n",
              "      <td>False</td>\n",
              "      <td>A</td>\n",
              "      <td>151315</td>\n",
              "      <td>46.50</td>\n",
              "      <td>2.625</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>211.350143</td>\n",
              "      <td>8.106</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Store  Dept        Date  Weekly_Sales  IsHoliday Type    Size  Temperature  \\\n",
              "0      1     1  2010-02-05      24924.50      False    A  151315        42.31   \n",
              "1      1     1  2010-02-12      46039.49       True    A  151315        38.51   \n",
              "2      1     1  2010-02-19      41595.55      False    A  151315        39.93   \n",
              "3      1     1  2010-02-26      19403.54      False    A  151315        46.63   \n",
              "4      1     1  2010-03-05      21827.90      False    A  151315        46.50   \n",
              "\n",
              "   Fuel_Price  MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5  \\\n",
              "0       2.572        NaN        NaN        NaN        NaN        NaN   \n",
              "1       2.548        NaN        NaN        NaN        NaN        NaN   \n",
              "2       2.514        NaN        NaN        NaN        NaN        NaN   \n",
              "3       2.561        NaN        NaN        NaN        NaN        NaN   \n",
              "4       2.625        NaN        NaN        NaN        NaN        NaN   \n",
              "\n",
              "          CPI  Unemployment  \n",
              "0  211.096358         8.106  \n",
              "1  211.242170         8.106  \n",
              "2  211.289143         8.106  \n",
              "3  211.319643         8.106  \n",
              "4  211.350143         8.106  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Unificação dos Dados (Merge)\n",
        "\n",
        "# Para o conjunto de treino\n",
        "df_train_merged = pd.merge(df_train, df_stores, on='Store', how='left')\n",
        "df_train_merged = pd.merge(df_train_merged, df_features, on=['Store', 'Date', 'IsHoliday'], how='left')\n",
        "\n",
        "# Exibir as 5 primeiras linhas do dataframe merged\n",
        "print(\"\\nExibindo as 5 primeiras linhas do dataframe df_train_merged:\")\n",
        "display(df_train_merged.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "IXrr51SllUBj",
        "outputId": "23cc5eef-3f1c-441a-e76a-7d890516e822"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Exibindo as 5 primeiras linhas do dataframe df_test_merged:\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Store",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Dept",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Date",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "IsHoliday",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Type",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Size",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Temperature",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_Price",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown2",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown3",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown4",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown5",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "CPI",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Unemployment",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "5bb71147-d2f0-49ab-ba2f-1cd75bc0727f",
              "rows": [
                [
                  "0",
                  "1",
                  "1",
                  "2012-11-02",
                  "False",
                  "A",
                  "151315",
                  "55.32",
                  "3.386",
                  "6766.44",
                  "5147.7",
                  "50.82",
                  "3639.9",
                  "2737.42",
                  "223.4627793",
                  "6.573"
                ],
                [
                  "1",
                  "1",
                  "1",
                  "2012-11-09",
                  "False",
                  "A",
                  "151315",
                  "61.24",
                  "3.314",
                  "11421.32",
                  "3370.89",
                  "40.28",
                  "4646.79",
                  "6154.16",
                  "223.4813073",
                  "6.573"
                ],
                [
                  "2",
                  "1",
                  "1",
                  "2012-11-16",
                  "False",
                  "A",
                  "151315",
                  "52.92",
                  "3.252",
                  "9696.28",
                  "292.1",
                  "103.78",
                  "1133.15",
                  "6612.69",
                  "223.5129105",
                  "6.573"
                ],
                [
                  "3",
                  "1",
                  "1",
                  "2012-11-23",
                  "True",
                  "A",
                  "151315",
                  "56.23",
                  "3.211",
                  "883.59",
                  "4.17",
                  "74910.32",
                  "209.91",
                  "303.32",
                  "223.5619474",
                  "6.573"
                ],
                [
                  "4",
                  "1",
                  "1",
                  "2012-11-30",
                  "False",
                  "A",
                  "151315",
                  "52.34",
                  "3.207",
                  "2460.03",
                  null,
                  "3838.35",
                  "150.57",
                  "6966.34",
                  "223.6109842",
                  "6.573"
                ]
              ],
              "shape": {
                "columns": 15,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Dept</th>\n",
              "      <th>Date</th>\n",
              "      <th>IsHoliday</th>\n",
              "      <th>Type</th>\n",
              "      <th>Size</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Fuel_Price</th>\n",
              "      <th>MarkDown1</th>\n",
              "      <th>MarkDown2</th>\n",
              "      <th>MarkDown3</th>\n",
              "      <th>MarkDown4</th>\n",
              "      <th>MarkDown5</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Unemployment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2012-11-02</td>\n",
              "      <td>False</td>\n",
              "      <td>A</td>\n",
              "      <td>151315</td>\n",
              "      <td>55.32</td>\n",
              "      <td>3.386</td>\n",
              "      <td>6766.44</td>\n",
              "      <td>5147.70</td>\n",
              "      <td>50.82</td>\n",
              "      <td>3639.90</td>\n",
              "      <td>2737.42</td>\n",
              "      <td>223.462779</td>\n",
              "      <td>6.573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2012-11-09</td>\n",
              "      <td>False</td>\n",
              "      <td>A</td>\n",
              "      <td>151315</td>\n",
              "      <td>61.24</td>\n",
              "      <td>3.314</td>\n",
              "      <td>11421.32</td>\n",
              "      <td>3370.89</td>\n",
              "      <td>40.28</td>\n",
              "      <td>4646.79</td>\n",
              "      <td>6154.16</td>\n",
              "      <td>223.481307</td>\n",
              "      <td>6.573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2012-11-16</td>\n",
              "      <td>False</td>\n",
              "      <td>A</td>\n",
              "      <td>151315</td>\n",
              "      <td>52.92</td>\n",
              "      <td>3.252</td>\n",
              "      <td>9696.28</td>\n",
              "      <td>292.10</td>\n",
              "      <td>103.78</td>\n",
              "      <td>1133.15</td>\n",
              "      <td>6612.69</td>\n",
              "      <td>223.512911</td>\n",
              "      <td>6.573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2012-11-23</td>\n",
              "      <td>True</td>\n",
              "      <td>A</td>\n",
              "      <td>151315</td>\n",
              "      <td>56.23</td>\n",
              "      <td>3.211</td>\n",
              "      <td>883.59</td>\n",
              "      <td>4.17</td>\n",
              "      <td>74910.32</td>\n",
              "      <td>209.91</td>\n",
              "      <td>303.32</td>\n",
              "      <td>223.561947</td>\n",
              "      <td>6.573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2012-11-30</td>\n",
              "      <td>False</td>\n",
              "      <td>A</td>\n",
              "      <td>151315</td>\n",
              "      <td>52.34</td>\n",
              "      <td>3.207</td>\n",
              "      <td>2460.03</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3838.35</td>\n",
              "      <td>150.57</td>\n",
              "      <td>6966.34</td>\n",
              "      <td>223.610984</td>\n",
              "      <td>6.573</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Store  Dept        Date  IsHoliday Type    Size  Temperature  Fuel_Price  \\\n",
              "0      1     1  2012-11-02      False    A  151315        55.32       3.386   \n",
              "1      1     1  2012-11-09      False    A  151315        61.24       3.314   \n",
              "2      1     1  2012-11-16      False    A  151315        52.92       3.252   \n",
              "3      1     1  2012-11-23       True    A  151315        56.23       3.211   \n",
              "4      1     1  2012-11-30      False    A  151315        52.34       3.207   \n",
              "\n",
              "   MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5         CPI  \\\n",
              "0    6766.44    5147.70      50.82    3639.90    2737.42  223.462779   \n",
              "1   11421.32    3370.89      40.28    4646.79    6154.16  223.481307   \n",
              "2    9696.28     292.10     103.78    1133.15    6612.69  223.512911   \n",
              "3     883.59       4.17   74910.32     209.91     303.32  223.561947   \n",
              "4    2460.03        NaN    3838.35     150.57    6966.34  223.610984   \n",
              "\n",
              "   Unemployment  \n",
              "0         6.573  \n",
              "1         6.573  \n",
              "2         6.573  \n",
              "3         6.573  \n",
              "4         6.573  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Para o conjunto de teste\n",
        "df_test_merged = pd.merge(df_test, df_stores, on='Store', how='left')\n",
        "df_test_merged = pd.merge(df_test_merged, df_features, on=['Store', 'Date', 'IsHoliday'], how='left')\n",
        "\n",
        "print(\"\\nExibindo as 5 primeiras linhas do dataframe df_test_merged:\")\n",
        "display(df_test_merged.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ8SxC7Ul164"
      },
      "source": [
        "# Limpeza de Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA6lHtkwmTsM"
      },
      "source": [
        "Visualização dos dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8hprdpgl22z",
        "outputId": "e7a927ea-fb09-4fd9-b805-a97ab695db2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Informações sobre df_train_merged:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 421570 entries, 0 to 421569\n",
            "Data columns (total 16 columns):\n",
            " #   Column        Non-Null Count   Dtype  \n",
            "---  ------        --------------   -----  \n",
            " 0   Store         421570 non-null  int64  \n",
            " 1   Dept          421570 non-null  int64  \n",
            " 2   Date          421570 non-null  object \n",
            " 3   Weekly_Sales  421570 non-null  float64\n",
            " 4   IsHoliday     421570 non-null  bool   \n",
            " 5   Type          421570 non-null  object \n",
            " 6   Size          421570 non-null  int64  \n",
            " 7   Temperature   421570 non-null  float64\n",
            " 8   Fuel_Price    421570 non-null  float64\n",
            " 9   MarkDown1     150681 non-null  float64\n",
            " 10  MarkDown2     111248 non-null  float64\n",
            " 11  MarkDown3     137091 non-null  float64\n",
            " 12  MarkDown4     134967 non-null  float64\n",
            " 13  MarkDown5     151432 non-null  float64\n",
            " 14  CPI           421570 non-null  float64\n",
            " 15  Unemployment  421570 non-null  float64\n",
            "dtypes: bool(1), float64(10), int64(3), object(2)\n",
            "memory usage: 48.6+ MB\n",
            "\n",
            "Informações sobre df_test_merged:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 115064 entries, 0 to 115063\n",
            "Data columns (total 15 columns):\n",
            " #   Column        Non-Null Count   Dtype  \n",
            "---  ------        --------------   -----  \n",
            " 0   Store         115064 non-null  int64  \n",
            " 1   Dept          115064 non-null  int64  \n",
            " 2   Date          115064 non-null  object \n",
            " 3   IsHoliday     115064 non-null  bool   \n",
            " 4   Type          115064 non-null  object \n",
            " 5   Size          115064 non-null  int64  \n",
            " 6   Temperature   115064 non-null  float64\n",
            " 7   Fuel_Price    115064 non-null  float64\n",
            " 8   MarkDown1     114915 non-null  float64\n",
            " 9   MarkDown2     86437 non-null   float64\n",
            " 10  MarkDown3     105235 non-null  float64\n",
            " 11  MarkDown4     102176 non-null  float64\n",
            " 12  MarkDown5     115064 non-null  float64\n",
            " 13  CPI           76902 non-null   float64\n",
            " 14  Unemployment  76902 non-null   float64\n",
            "dtypes: bool(1), float64(9), int64(3), object(2)\n",
            "memory usage: 12.4+ MB\n"
          ]
        }
      ],
      "source": [
        "print(\"Informações sobre df_train_merged:\")\n",
        "df_train_merged.info()\n",
        "\n",
        "print(\"\\nInformações sobre df_test_merged:\")\n",
        "df_test_merged.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcX8qziBmRPm",
        "outputId": "d3577a3b-ea13-4d45-9c33-d52c5c735b65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 421570 entries, 0 to 421569\n",
            "Data columns (total 16 columns):\n",
            " #   Column        Non-Null Count   Dtype         \n",
            "---  ------        --------------   -----         \n",
            " 0   Store         421570 non-null  int64         \n",
            " 1   Dept          421570 non-null  int64         \n",
            " 2   Date          421570 non-null  datetime64[ns]\n",
            " 3   Weekly_Sales  421570 non-null  float64       \n",
            " 4   IsHoliday     421570 non-null  bool          \n",
            " 5   Type          421570 non-null  object        \n",
            " 6   Size          421570 non-null  int64         \n",
            " 7   Temperature   421570 non-null  float64       \n",
            " 8   Fuel_Price    421570 non-null  float64       \n",
            " 9   MarkDown1     150681 non-null  float64       \n",
            " 10  MarkDown2     111248 non-null  float64       \n",
            " 11  MarkDown3     137091 non-null  float64       \n",
            " 12  MarkDown4     134967 non-null  float64       \n",
            " 13  MarkDown5     151432 non-null  float64       \n",
            " 14  CPI           421570 non-null  float64       \n",
            " 15  Unemployment  421570 non-null  float64       \n",
            "dtypes: bool(1), datetime64[ns](1), float64(10), int64(3), object(1)\n",
            "memory usage: 48.6+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 115064 entries, 0 to 115063\n",
            "Data columns (total 15 columns):\n",
            " #   Column        Non-Null Count   Dtype         \n",
            "---  ------        --------------   -----         \n",
            " 0   Store         115064 non-null  int64         \n",
            " 1   Dept          115064 non-null  int64         \n",
            " 2   Date          115064 non-null  datetime64[ns]\n",
            " 3   IsHoliday     115064 non-null  bool          \n",
            " 4   Type          115064 non-null  object        \n",
            " 5   Size          115064 non-null  int64         \n",
            " 6   Temperature   115064 non-null  float64       \n",
            " 7   Fuel_Price    115064 non-null  float64       \n",
            " 8   MarkDown1     114915 non-null  float64       \n",
            " 9   MarkDown2     86437 non-null   float64       \n",
            " 10  MarkDown3     105235 non-null  float64       \n",
            " 11  MarkDown4     102176 non-null  float64       \n",
            " 12  MarkDown5     115064 non-null  float64       \n",
            " 13  CPI           76902 non-null   float64       \n",
            " 14  Unemployment  76902 non-null   float64       \n",
            "dtypes: bool(1), datetime64[ns](1), float64(9), int64(3), object(1)\n",
            "memory usage: 12.4+ MB\n"
          ]
        }
      ],
      "source": [
        "# Converter 'Date' para datetime\n",
        "df_train_merged['Date'] = pd.to_datetime(df_train_merged['Date'])\n",
        "df_test_merged['Date'] = pd.to_datetime(df_test_merged['Date'])\n",
        "\n",
        "df_train_merged.info()\n",
        "df_test_merged.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        },
        "id": "Cmh88bwQmwkC",
        "outputId": "fc1f51e3-1af9-424b-93f1-d8a358411ea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Estatísticas Descritivas: df_train_merged ---\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Store",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Dept",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Date",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "Weekly_Sales",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "IsHoliday",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "Type",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "Size",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Temperature",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_Price",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown2",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown3",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown4",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown5",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "CPI",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Unemployment",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "1d0a25b5-9031-4d0b-a27e-932b90b291ad",
              "rows": [
                [
                  "count",
                  "421570.0",
                  "421570.0",
                  "421570",
                  "421570.0",
                  "421570",
                  "421570",
                  "421570.0",
                  "421570.0",
                  "421570.0",
                  "150681.0",
                  "111248.0",
                  "137091.0",
                  "134967.0",
                  "151432.0",
                  "421570.0",
                  "421570.0"
                ],
                [
                  "unique",
                  null,
                  null,
                  null,
                  null,
                  "2",
                  "3",
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null
                ],
                [
                  "top",
                  null,
                  null,
                  null,
                  null,
                  "False",
                  "A",
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null
                ],
                [
                  "freq",
                  null,
                  null,
                  null,
                  null,
                  "391909",
                  "215478",
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null
                ],
                [
                  "mean",
                  "22.200545579619043",
                  "44.26031738501317",
                  "2011-06-18 08:30:31.963375104",
                  "15981.25812346704",
                  null,
                  null,
                  "136727.91573878596",
                  "60.09005873283201",
                  "3.361026527029912",
                  "7246.420195910568",
                  "3334.628621098807",
                  "1439.4213841900637",
                  "3383.1682560922304",
                  "4628.975079177453",
                  "171.20194682296346",
                  "7.960288694641462"
                ],
                [
                  "min",
                  "1.0",
                  "1.0",
                  "2010-02-05 00:00:00",
                  "-4988.94",
                  null,
                  null,
                  "34875.0",
                  "-2.06",
                  "2.472",
                  "0.27",
                  "-265.76",
                  "-29.1",
                  "0.22",
                  "135.16",
                  "126.064",
                  "3.879"
                ],
                [
                  "25%",
                  "11.0",
                  "18.0",
                  "2010-10-08 00:00:00",
                  "2079.6499999999996",
                  null,
                  null,
                  "93638.0",
                  "46.68",
                  "2.933",
                  "2240.27",
                  "41.6",
                  "5.08",
                  "504.22",
                  "1878.44",
                  "132.0226667",
                  "6.891"
                ],
                [
                  "50%",
                  "22.0",
                  "37.0",
                  "2011-06-17 00:00:00",
                  "7612.03",
                  null,
                  null,
                  "140167.0",
                  "62.09",
                  "3.452",
                  "5347.45",
                  "192.0",
                  "24.6",
                  "1481.31",
                  "3359.45",
                  "182.3187801",
                  "7.866"
                ],
                [
                  "75%",
                  "33.0",
                  "74.0",
                  "2012-02-24 00:00:00",
                  "20205.8525",
                  null,
                  null,
                  "202505.0",
                  "74.28",
                  "3.738",
                  "9210.9",
                  "1926.94",
                  "103.99",
                  "3595.04",
                  "5563.8",
                  "212.4169928",
                  "8.572"
                ],
                [
                  "max",
                  "45.0",
                  "99.0",
                  "2012-10-26 00:00:00",
                  "693099.36",
                  null,
                  null,
                  "219622.0",
                  "100.14",
                  "4.468",
                  "88646.76",
                  "104519.54",
                  "141630.61",
                  "67474.85",
                  "108519.28",
                  "227.2328068",
                  "14.313"
                ],
                [
                  "std",
                  "12.785297389901771",
                  "30.492054015760527",
                  null,
                  "22711.18351916313",
                  null,
                  null,
                  "60980.58332810464",
                  "18.447931147614106",
                  "0.45851453712773876",
                  "8291.221345474767",
                  "9475.357325457915",
                  "9623.078290313179",
                  "6292.384030869798",
                  "5962.887455254558",
                  "39.1592756230151",
                  "1.863296038430238"
                ]
              ],
              "shape": {
                "columns": 16,
                "rows": 11
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Dept</th>\n",
              "      <th>Date</th>\n",
              "      <th>Weekly_Sales</th>\n",
              "      <th>IsHoliday</th>\n",
              "      <th>Type</th>\n",
              "      <th>Size</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Fuel_Price</th>\n",
              "      <th>MarkDown1</th>\n",
              "      <th>MarkDown2</th>\n",
              "      <th>MarkDown3</th>\n",
              "      <th>MarkDown4</th>\n",
              "      <th>MarkDown5</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Unemployment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>421570.000000</td>\n",
              "      <td>421570.000000</td>\n",
              "      <td>421570</td>\n",
              "      <td>421570.000000</td>\n",
              "      <td>421570</td>\n",
              "      <td>421570</td>\n",
              "      <td>421570.000000</td>\n",
              "      <td>421570.000000</td>\n",
              "      <td>421570.000000</td>\n",
              "      <td>150681.000000</td>\n",
              "      <td>111248.000000</td>\n",
              "      <td>137091.000000</td>\n",
              "      <td>134967.000000</td>\n",
              "      <td>151432.000000</td>\n",
              "      <td>421570.000000</td>\n",
              "      <td>421570.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>391909</td>\n",
              "      <td>215478</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>22.200546</td>\n",
              "      <td>44.260317</td>\n",
              "      <td>2011-06-18 08:30:31.963375104</td>\n",
              "      <td>15981.258123</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>136727.915739</td>\n",
              "      <td>60.090059</td>\n",
              "      <td>3.361027</td>\n",
              "      <td>7246.420196</td>\n",
              "      <td>3334.628621</td>\n",
              "      <td>1439.421384</td>\n",
              "      <td>3383.168256</td>\n",
              "      <td>4628.975079</td>\n",
              "      <td>171.201947</td>\n",
              "      <td>7.960289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2010-02-05 00:00:00</td>\n",
              "      <td>-4988.940000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34875.000000</td>\n",
              "      <td>-2.060000</td>\n",
              "      <td>2.472000</td>\n",
              "      <td>0.270000</td>\n",
              "      <td>-265.760000</td>\n",
              "      <td>-29.100000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>135.160000</td>\n",
              "      <td>126.064000</td>\n",
              "      <td>3.879000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>2010-10-08 00:00:00</td>\n",
              "      <td>2079.650000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>93638.000000</td>\n",
              "      <td>46.680000</td>\n",
              "      <td>2.933000</td>\n",
              "      <td>2240.270000</td>\n",
              "      <td>41.600000</td>\n",
              "      <td>5.080000</td>\n",
              "      <td>504.220000</td>\n",
              "      <td>1878.440000</td>\n",
              "      <td>132.022667</td>\n",
              "      <td>6.891000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>22.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>2011-06-17 00:00:00</td>\n",
              "      <td>7612.030000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>140167.000000</td>\n",
              "      <td>62.090000</td>\n",
              "      <td>3.452000</td>\n",
              "      <td>5347.450000</td>\n",
              "      <td>192.000000</td>\n",
              "      <td>24.600000</td>\n",
              "      <td>1481.310000</td>\n",
              "      <td>3359.450000</td>\n",
              "      <td>182.318780</td>\n",
              "      <td>7.866000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>33.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>2012-02-24 00:00:00</td>\n",
              "      <td>20205.852500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>202505.000000</td>\n",
              "      <td>74.280000</td>\n",
              "      <td>3.738000</td>\n",
              "      <td>9210.900000</td>\n",
              "      <td>1926.940000</td>\n",
              "      <td>103.990000</td>\n",
              "      <td>3595.040000</td>\n",
              "      <td>5563.800000</td>\n",
              "      <td>212.416993</td>\n",
              "      <td>8.572000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>45.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>2012-10-26 00:00:00</td>\n",
              "      <td>693099.360000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>219622.000000</td>\n",
              "      <td>100.140000</td>\n",
              "      <td>4.468000</td>\n",
              "      <td>88646.760000</td>\n",
              "      <td>104519.540000</td>\n",
              "      <td>141630.610000</td>\n",
              "      <td>67474.850000</td>\n",
              "      <td>108519.280000</td>\n",
              "      <td>227.232807</td>\n",
              "      <td>14.313000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.785297</td>\n",
              "      <td>30.492054</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22711.183519</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>60980.583328</td>\n",
              "      <td>18.447931</td>\n",
              "      <td>0.458515</td>\n",
              "      <td>8291.221345</td>\n",
              "      <td>9475.357325</td>\n",
              "      <td>9623.078290</td>\n",
              "      <td>6292.384031</td>\n",
              "      <td>5962.887455</td>\n",
              "      <td>39.159276</td>\n",
              "      <td>1.863296</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Store           Dept                           Date  \\\n",
              "count   421570.000000  421570.000000                         421570   \n",
              "unique            NaN            NaN                            NaN   \n",
              "top               NaN            NaN                            NaN   \n",
              "freq              NaN            NaN                            NaN   \n",
              "mean        22.200546      44.260317  2011-06-18 08:30:31.963375104   \n",
              "min          1.000000       1.000000            2010-02-05 00:00:00   \n",
              "25%         11.000000      18.000000            2010-10-08 00:00:00   \n",
              "50%         22.000000      37.000000            2011-06-17 00:00:00   \n",
              "75%         33.000000      74.000000            2012-02-24 00:00:00   \n",
              "max         45.000000      99.000000            2012-10-26 00:00:00   \n",
              "std         12.785297      30.492054                            NaN   \n",
              "\n",
              "         Weekly_Sales IsHoliday    Type           Size    Temperature  \\\n",
              "count   421570.000000    421570  421570  421570.000000  421570.000000   \n",
              "unique            NaN         2       3            NaN            NaN   \n",
              "top               NaN     False       A            NaN            NaN   \n",
              "freq              NaN    391909  215478            NaN            NaN   \n",
              "mean     15981.258123       NaN     NaN  136727.915739      60.090059   \n",
              "min      -4988.940000       NaN     NaN   34875.000000      -2.060000   \n",
              "25%       2079.650000       NaN     NaN   93638.000000      46.680000   \n",
              "50%       7612.030000       NaN     NaN  140167.000000      62.090000   \n",
              "75%      20205.852500       NaN     NaN  202505.000000      74.280000   \n",
              "max     693099.360000       NaN     NaN  219622.000000     100.140000   \n",
              "std      22711.183519       NaN     NaN   60980.583328      18.447931   \n",
              "\n",
              "           Fuel_Price      MarkDown1      MarkDown2      MarkDown3  \\\n",
              "count   421570.000000  150681.000000  111248.000000  137091.000000   \n",
              "unique            NaN            NaN            NaN            NaN   \n",
              "top               NaN            NaN            NaN            NaN   \n",
              "freq              NaN            NaN            NaN            NaN   \n",
              "mean         3.361027    7246.420196    3334.628621    1439.421384   \n",
              "min          2.472000       0.270000    -265.760000     -29.100000   \n",
              "25%          2.933000    2240.270000      41.600000       5.080000   \n",
              "50%          3.452000    5347.450000     192.000000      24.600000   \n",
              "75%          3.738000    9210.900000    1926.940000     103.990000   \n",
              "max          4.468000   88646.760000  104519.540000  141630.610000   \n",
              "std          0.458515    8291.221345    9475.357325    9623.078290   \n",
              "\n",
              "            MarkDown4      MarkDown5            CPI   Unemployment  \n",
              "count   134967.000000  151432.000000  421570.000000  421570.000000  \n",
              "unique            NaN            NaN            NaN            NaN  \n",
              "top               NaN            NaN            NaN            NaN  \n",
              "freq              NaN            NaN            NaN            NaN  \n",
              "mean      3383.168256    4628.975079     171.201947       7.960289  \n",
              "min          0.220000     135.160000     126.064000       3.879000  \n",
              "25%        504.220000    1878.440000     132.022667       6.891000  \n",
              "50%       1481.310000    3359.450000     182.318780       7.866000  \n",
              "75%       3595.040000    5563.800000     212.416993       8.572000  \n",
              "max      67474.850000  108519.280000     227.232807      14.313000  \n",
              "std       6292.384031    5962.887455      39.159276       1.863296  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Estatísticas Descritivas: df_test_merged ---\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Store",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Dept",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Date",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "IsHoliday",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "Type",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "Size",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Temperature",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_Price",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown2",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown3",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown4",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown5",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "CPI",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Unemployment",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "f8eb64ec-9db2-4a2a-a327-b4ecc7c7e29f",
              "rows": [
                [
                  "count",
                  "115064.0",
                  "115064.0",
                  "115064",
                  "115064",
                  "115064",
                  "115064.0",
                  "115064.0",
                  "115064.0",
                  "114915.0",
                  "86437.0",
                  "105235.0",
                  "102176.0",
                  "115064.0",
                  "76902.0",
                  "76902.0"
                ],
                [
                  "unique",
                  null,
                  null,
                  null,
                  "2",
                  "3",
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null
                ],
                [
                  "top",
                  null,
                  null,
                  null,
                  "False",
                  "A",
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null
                ],
                [
                  "freq",
                  null,
                  null,
                  null,
                  "106136",
                  "58713",
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null
                ],
                [
                  "mean",
                  "22.2382065633039",
                  "44.33952409094069",
                  "2013-03-14 14:39:41.311270144",
                  null,
                  null,
                  "136497.68892094833",
                  "53.94180386567475",
                  "3.581546322046861",
                  "7689.216438933126",
                  "3734.0517294677047",
                  "2403.088666033164",
                  "3356.219071308331",
                  "3922.681188729751",
                  "176.9613466486034",
                  "6.8687331668877265"
                ],
                [
                  "min",
                  "1.0",
                  "1.0",
                  "2012-11-02 00:00:00",
                  null,
                  null,
                  "34875.0",
                  "-7.29",
                  "2.872",
                  "-2781.45",
                  "-35.74",
                  "-179.26",
                  "0.22",
                  "-185.17",
                  "131.2362258",
                  "3.684"
                ],
                [
                  "25%",
                  "11.0",
                  "18.0",
                  "2013-01-04 00:00:00",
                  null,
                  null,
                  "93638.0",
                  "39.82",
                  "3.431",
                  "1966.46",
                  "180.35",
                  "15.1",
                  "155.46",
                  "1309.3",
                  "138.4020333",
                  "5.771"
                ],
                [
                  "50%",
                  "22.0",
                  "37.0",
                  "2013-03-15 00:00:00",
                  null,
                  null,
                  "140167.0",
                  "54.47",
                  "3.606",
                  "4842.29",
                  "742.59",
                  "78.26",
                  "840.94",
                  "2390.43",
                  "192.3044449",
                  "6.806"
                ],
                [
                  "75%",
                  "33.0",
                  "74.0",
                  "2013-05-24 00:00:00",
                  null,
                  null,
                  "202505.0",
                  "67.35",
                  "3.766",
                  "9439.14",
                  "2735.67",
                  "272.58",
                  "3096.92",
                  "4227.27",
                  "223.2445318",
                  "8.036"
                ],
                [
                  "max",
                  "45.0",
                  "99.0",
                  "2013-07-26 00:00:00",
                  null,
                  null,
                  "219622.0",
                  "101.95",
                  "4.125",
                  "103184.98",
                  "71074.17",
                  "149483.31",
                  "65344.64",
                  "771448.1",
                  "228.9764563",
                  "10.199"
                ],
                [
                  "std",
                  "12.809929591381378",
                  "30.656410130032484",
                  null,
                  null,
                  null,
                  "61106.92643816325",
                  "18.724152888947696",
                  "0.23944193035703848",
                  "10698.760715652545",
                  "8323.495014319815",
                  "13767.939312964267",
                  "7570.501544698753",
                  "19445.150745269006",
                  "41.23996660332662",
                  "1.5834273529055343"
                ]
              ],
              "shape": {
                "columns": 15,
                "rows": 11
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Dept</th>\n",
              "      <th>Date</th>\n",
              "      <th>IsHoliday</th>\n",
              "      <th>Type</th>\n",
              "      <th>Size</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Fuel_Price</th>\n",
              "      <th>MarkDown1</th>\n",
              "      <th>MarkDown2</th>\n",
              "      <th>MarkDown3</th>\n",
              "      <th>MarkDown4</th>\n",
              "      <th>MarkDown5</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Unemployment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>115064.000000</td>\n",
              "      <td>115064.000000</td>\n",
              "      <td>115064</td>\n",
              "      <td>115064</td>\n",
              "      <td>115064</td>\n",
              "      <td>115064.000000</td>\n",
              "      <td>115064.000000</td>\n",
              "      <td>115064.000000</td>\n",
              "      <td>114915.000000</td>\n",
              "      <td>86437.000000</td>\n",
              "      <td>105235.000000</td>\n",
              "      <td>102176.000000</td>\n",
              "      <td>115064.000000</td>\n",
              "      <td>76902.000000</td>\n",
              "      <td>76902.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>106136</td>\n",
              "      <td>58713</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>22.238207</td>\n",
              "      <td>44.339524</td>\n",
              "      <td>2013-03-14 14:39:41.311270144</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>136497.688921</td>\n",
              "      <td>53.941804</td>\n",
              "      <td>3.581546</td>\n",
              "      <td>7689.216439</td>\n",
              "      <td>3734.051729</td>\n",
              "      <td>2403.088666</td>\n",
              "      <td>3356.219071</td>\n",
              "      <td>3922.681189</td>\n",
              "      <td>176.961347</td>\n",
              "      <td>6.868733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2012-11-02 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34875.000000</td>\n",
              "      <td>-7.290000</td>\n",
              "      <td>2.872000</td>\n",
              "      <td>-2781.450000</td>\n",
              "      <td>-35.740000</td>\n",
              "      <td>-179.260000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>-185.170000</td>\n",
              "      <td>131.236226</td>\n",
              "      <td>3.684000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>2013-01-04 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>93638.000000</td>\n",
              "      <td>39.820000</td>\n",
              "      <td>3.431000</td>\n",
              "      <td>1966.460000</td>\n",
              "      <td>180.350000</td>\n",
              "      <td>15.100000</td>\n",
              "      <td>155.460000</td>\n",
              "      <td>1309.300000</td>\n",
              "      <td>138.402033</td>\n",
              "      <td>5.771000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>22.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>2013-03-15 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>140167.000000</td>\n",
              "      <td>54.470000</td>\n",
              "      <td>3.606000</td>\n",
              "      <td>4842.290000</td>\n",
              "      <td>742.590000</td>\n",
              "      <td>78.260000</td>\n",
              "      <td>840.940000</td>\n",
              "      <td>2390.430000</td>\n",
              "      <td>192.304445</td>\n",
              "      <td>6.806000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>33.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>2013-05-24 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>202505.000000</td>\n",
              "      <td>67.350000</td>\n",
              "      <td>3.766000</td>\n",
              "      <td>9439.140000</td>\n",
              "      <td>2735.670000</td>\n",
              "      <td>272.580000</td>\n",
              "      <td>3096.920000</td>\n",
              "      <td>4227.270000</td>\n",
              "      <td>223.244532</td>\n",
              "      <td>8.036000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>45.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>2013-07-26 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>219622.000000</td>\n",
              "      <td>101.950000</td>\n",
              "      <td>4.125000</td>\n",
              "      <td>103184.980000</td>\n",
              "      <td>71074.170000</td>\n",
              "      <td>149483.310000</td>\n",
              "      <td>65344.640000</td>\n",
              "      <td>771448.100000</td>\n",
              "      <td>228.976456</td>\n",
              "      <td>10.199000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.809930</td>\n",
              "      <td>30.656410</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>61106.926438</td>\n",
              "      <td>18.724153</td>\n",
              "      <td>0.239442</td>\n",
              "      <td>10698.760716</td>\n",
              "      <td>8323.495014</td>\n",
              "      <td>13767.939313</td>\n",
              "      <td>7570.501545</td>\n",
              "      <td>19445.150745</td>\n",
              "      <td>41.239967</td>\n",
              "      <td>1.583427</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Store           Dept                           Date IsHoliday  \\\n",
              "count   115064.000000  115064.000000                         115064    115064   \n",
              "unique            NaN            NaN                            NaN         2   \n",
              "top               NaN            NaN                            NaN     False   \n",
              "freq              NaN            NaN                            NaN    106136   \n",
              "mean        22.238207      44.339524  2013-03-14 14:39:41.311270144       NaN   \n",
              "min          1.000000       1.000000            2012-11-02 00:00:00       NaN   \n",
              "25%         11.000000      18.000000            2013-01-04 00:00:00       NaN   \n",
              "50%         22.000000      37.000000            2013-03-15 00:00:00       NaN   \n",
              "75%         33.000000      74.000000            2013-05-24 00:00:00       NaN   \n",
              "max         45.000000      99.000000            2013-07-26 00:00:00       NaN   \n",
              "std         12.809930      30.656410                            NaN       NaN   \n",
              "\n",
              "          Type           Size    Temperature     Fuel_Price      MarkDown1  \\\n",
              "count   115064  115064.000000  115064.000000  115064.000000  114915.000000   \n",
              "unique       3            NaN            NaN            NaN            NaN   \n",
              "top          A            NaN            NaN            NaN            NaN   \n",
              "freq     58713            NaN            NaN            NaN            NaN   \n",
              "mean       NaN  136497.688921      53.941804       3.581546    7689.216439   \n",
              "min        NaN   34875.000000      -7.290000       2.872000   -2781.450000   \n",
              "25%        NaN   93638.000000      39.820000       3.431000    1966.460000   \n",
              "50%        NaN  140167.000000      54.470000       3.606000    4842.290000   \n",
              "75%        NaN  202505.000000      67.350000       3.766000    9439.140000   \n",
              "max        NaN  219622.000000     101.950000       4.125000  103184.980000   \n",
              "std        NaN   61106.926438      18.724153       0.239442   10698.760716   \n",
              "\n",
              "           MarkDown2      MarkDown3      MarkDown4      MarkDown5  \\\n",
              "count   86437.000000  105235.000000  102176.000000  115064.000000   \n",
              "unique           NaN            NaN            NaN            NaN   \n",
              "top              NaN            NaN            NaN            NaN   \n",
              "freq             NaN            NaN            NaN            NaN   \n",
              "mean     3734.051729    2403.088666    3356.219071    3922.681189   \n",
              "min       -35.740000    -179.260000       0.220000    -185.170000   \n",
              "25%       180.350000      15.100000     155.460000    1309.300000   \n",
              "50%       742.590000      78.260000     840.940000    2390.430000   \n",
              "75%      2735.670000     272.580000    3096.920000    4227.270000   \n",
              "max     71074.170000  149483.310000   65344.640000  771448.100000   \n",
              "std      8323.495014   13767.939313    7570.501545   19445.150745   \n",
              "\n",
              "                 CPI  Unemployment  \n",
              "count   76902.000000  76902.000000  \n",
              "unique           NaN           NaN  \n",
              "top              NaN           NaN  \n",
              "freq             NaN           NaN  \n",
              "mean      176.961347      6.868733  \n",
              "min       131.236226      3.684000  \n",
              "25%       138.402033      5.771000  \n",
              "50%       192.304445      6.806000  \n",
              "75%       223.244532      8.036000  \n",
              "max       228.976456     10.199000  \n",
              "std        41.239967      1.583427  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"--- Estatísticas Descritivas: df_train_merged ---\")\n",
        "display(df_train_merged.describe(include='all'))\n",
        "\n",
        "print(\"\\n--- Estatísticas Descritivas: df_test_merged ---\")\n",
        "display(df_test_merged.describe(include='all'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc08Y00YozYQ"
      },
      "source": [
        "## Tratamento de Weekly_Sales Negativas e Colunas MarkDown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bd3s4Jgoxd6",
        "outputId": "b762fca4-ce8f-4fa2-b1f7-493bf2fdc42c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de Weekly_Sales negativas: 1285\n",
            "Substituindo Weekly_Sales negativas por 0...\n",
            "Verificação - Novo mínimo de Weekly_Sales: 0.0\n"
          ]
        }
      ],
      "source": [
        "num_vendas_negativas = (df_train_merged['Weekly_Sales'] < 0).sum()\n",
        "print(f\"Número de Weekly_Sales negativas: {num_vendas_negativas}\")\n",
        "if num_vendas_negativas > 0:\n",
        "    print(\"Substituindo Weekly_Sales negativas por 0...\")\n",
        "    df_train_merged.loc[df_train_merged['Weekly_Sales'] < 0, 'Weekly_Sales'] = 0\n",
        "    print(f\"Verificação - Novo mínimo de Weekly_Sales: {df_train_merged['Weekly_Sales'].min()}\")\n",
        "else:\n",
        "    print(\"Nenhuma Weekly_Sales negativa encontrada.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24qVaJw7pLtM",
        "outputId": "dc5bd356-3b30-4eae-e44b-f4773e0c0e84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Tratando Weekly_Sales negativas em df_train_merged ---\n",
            "Nenhuma Weekly_Sales negativa encontrada em df_train_merged.\n",
            "\n",
            "--- Tratando MarkDowns negativos em df_train_merged ---\n",
            "Encontrados 1311 valores negativos em MarkDown2. Substituindo por 0...\n",
            "Verificação - Novo mínimo de MarkDown2: 0.0\n",
            "Encontrados 257 valores negativos em MarkDown3. Substituindo por 0...\n",
            "Verificação - Novo mínimo de MarkDown3: 0.0\n",
            "\n",
            "--- Tratando MarkDowns negativos em df_test_merged ---\n",
            "Encontrados 412 valores negativos em MarkDown2. Substituindo por 0...\n",
            "Verificação - Novo mínimo de MarkDown2: 0.0\n",
            "Encontrados 589 valores negativos em MarkDown3. Substituindo por 0...\n",
            "Verificação - Novo mínimo de MarkDown3: 0.0\n",
            "\n",
            "Tratamento de valores negativos concluído!\n"
          ]
        }
      ],
      "source": [
        "# 1. Tratamento de Weekly_Sales negativas em df_train_merged\n",
        "print(\"--- Tratando Weekly_Sales negativas em df_train_merged ---\")\n",
        "num_vendas_negativas = (df_train_merged['Weekly_Sales'] < 0).sum()\n",
        "if num_vendas_negativas > 0:\n",
        "    print(f\"Encontradas {num_vendas_negativas} Weekly_Sales negativas. Substituindo por 0...\")\n",
        "    df_train_merged.loc[df_train_merged['Weekly_Sales'] < 0, 'Weekly_Sales'] = 0\n",
        "    print(f\"Verificação - Novo mínimo de Weekly_Sales: {df_train_merged['Weekly_Sales'].min()}\")\n",
        "else:\n",
        "    print(\"Nenhuma Weekly_Sales negativa encontrada em df_train_merged.\")\n",
        "\n",
        "# 2. Tratamento de MarkDowns negativos\n",
        "\n",
        "markdown_cols_to_check = ['MarkDown2', 'MarkDown3']\n",
        "\n",
        "# Tratamento para df_train_merged\n",
        "print(\"\\n--- Tratando MarkDowns negativos em df_train_merged ---\")\n",
        "for col in markdown_cols_to_check:\n",
        "    if col in df_train_merged.columns:\n",
        "        num_neg_markdown_train = (df_train_merged[col] < 0).sum()\n",
        "        if num_neg_markdown_train > 0:\n",
        "            print(f\"Encontrados {num_neg_markdown_train} valores negativos em {col}. Substituindo por 0...\")\n",
        "            df_train_merged.loc[df_train_merged[col] < 0, col] = 0\n",
        "            print(f\"Verificação - Novo mínimo de {col}: {df_train_merged[col].min()}\")\n",
        "        else:\n",
        "            print(f\"Nenhum valor negativo encontrado em {col} no df_train_merged.\")\n",
        "    else:\n",
        "        print(f\"Coluna {col} não encontrada em df_train_merged.\")\n",
        "\n",
        "# Tratamento para df_test_merged\n",
        "print(\"\\n--- Tratando MarkDowns negativos em df_test_merged ---\")\n",
        "for col in markdown_cols_to_check:\n",
        "    if col in df_test_merged.columns:\n",
        "        num_neg_markdown_test = (df_test_merged[col] < 0).sum()\n",
        "        if num_neg_markdown_test > 0:\n",
        "            print(f\"Encontrados {num_neg_markdown_test} valores negativos em {col}. Substituindo por 0...\")\n",
        "            df_test_merged.loc[df_test_merged[col] < 0, col] = 0\n",
        "            print(f\"Verificação - Novo mínimo de {col}: {df_test_merged[col].min()}\")\n",
        "        else:\n",
        "            print(f\"Nenhum valor negativo encontrado em {col} no df_test_merged.\")\n",
        "    else:\n",
        "        print(f\"Coluna {col} não encontrada em df_test_merged.\")\n",
        "\n",
        "print(\"\\nTratamento de valores negativos concluído!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNfskG7voTmg",
        "outputId": "6de9178e-f9e7-498f-b722-3e0929784c7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Análise de MarkDown1 em df_train_merged:\n",
            "Número de valores negativos: 0\n",
            "count    0.0\n",
            "mean     NaN\n",
            "std      NaN\n",
            "min      NaN\n",
            "25%      NaN\n",
            "50%      NaN\n",
            "75%      NaN\n",
            "max      NaN\n",
            "Name: MarkDown1, dtype: float64\n",
            "\n",
            "Análise de MarkDown2 em df_train_merged:\n",
            "Número de valores negativos: 0\n",
            "count    0.0\n",
            "mean     NaN\n",
            "std      NaN\n",
            "min      NaN\n",
            "25%      NaN\n",
            "50%      NaN\n",
            "75%      NaN\n",
            "max      NaN\n",
            "Name: MarkDown2, dtype: float64\n",
            "\n",
            "Análise de MarkDown3 em df_train_merged:\n",
            "Número de valores negativos: 0\n",
            "count    0.0\n",
            "mean     NaN\n",
            "std      NaN\n",
            "min      NaN\n",
            "25%      NaN\n",
            "50%      NaN\n",
            "75%      NaN\n",
            "max      NaN\n",
            "Name: MarkDown3, dtype: float64\n",
            "\n",
            "Análise de MarkDown4 em df_train_merged:\n",
            "Número de valores negativos: 0\n",
            "count    0.0\n",
            "mean     NaN\n",
            "std      NaN\n",
            "min      NaN\n",
            "25%      NaN\n",
            "50%      NaN\n",
            "75%      NaN\n",
            "max      NaN\n",
            "Name: MarkDown4, dtype: float64\n",
            "\n",
            "Análise de MarkDown5 em df_train_merged:\n",
            "Número de valores negativos: 0\n",
            "count    0.0\n",
            "mean     NaN\n",
            "std      NaN\n",
            "min      NaN\n",
            "25%      NaN\n",
            "50%      NaN\n",
            "75%      NaN\n",
            "max      NaN\n",
            "Name: MarkDown5, dtype: float64\n"
          ]
        }
      ],
      "source": [
        " # Validando valores negaticos:\n",
        "\n",
        "for i in range(1, 6):\n",
        "    col_name = f'MarkDown{i}'\n",
        "    print(f\"\\nAnálise de {col_name} em df_train_merged:\")\n",
        "    print(f\"Número de valores negativos: {(df_train_merged[col_name] < 0).sum()}\")\n",
        "    print(df_train_merged[df_train_merged[col_name] < 0][col_name].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5JQp0a7p9Iw"
      },
      "source": [
        "## Verificação de Duplicatas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCK1hT2zp98P",
        "outputId": "8f6fc69e-1c53-450a-eb3a-5bc08928cb0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Número de linhas duplicadas em df_train_merged: 0\n",
            "\n",
            "Número de linhas duplicadas em df_test_merged: 0\n"
          ]
        }
      ],
      "source": [
        "# Para df_train_merged\n",
        "num_duplicatas_treino = df_train_merged.duplicated().sum()\n",
        "print(f\"\\nNúmero de linhas duplicadas em df_train_merged: {num_duplicatas_treino}\")\n",
        "if num_duplicatas_treino > 0:\n",
        "    print(f\"Removendo {num_duplicatas_treino} linhas duplicadas de df_train_merged...\")\n",
        "    df_train_merged.drop_duplicates(inplace=True)\n",
        "    df_train_merged.reset_index(drop=True, inplace=True) # Opcional: resetar o índice\n",
        "    print(f\"Novo shape de df_train_merged: {df_train_merged.shape}\")\n",
        "\n",
        "# Para df_test_merged\n",
        "num_duplicatas_teste = df_test_merged.duplicated().sum()\n",
        "print(f\"\\nNúmero de linhas duplicadas em df_test_merged: {num_duplicatas_teste}\")\n",
        "if num_duplicatas_teste > 0:\n",
        "    print(f\"Removendo {num_duplicatas_teste} linhas duplicadas de df_test_merged...\")\n",
        "    df_test_merged.drop_duplicates(inplace=True)\n",
        "    df_test_merged.reset_index(drop=True, inplace=True) # Opcional: resetar o índice\n",
        "    print(f\"Novo shape de df_test_merged: {df_test_merged.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2rU-qiIrAVW"
      },
      "source": [
        "## Tratamento de Valores Ausentes (NaNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMktjj5xrEfY"
      },
      "source": [
        "Verificando NaNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRPYyyi1rBPN",
        "outputId": "e7ccd6f0-f931-44c2-c803-8fe7b4528535"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Verificando NaNs em df_train_merged ANTES do tratamento ---\n",
            "Store                0\n",
            "Dept                 0\n",
            "Date                 0\n",
            "Weekly_Sales         0\n",
            "IsHoliday            0\n",
            "Type                 0\n",
            "Size                 0\n",
            "Temperature          0\n",
            "Fuel_Price           0\n",
            "MarkDown1       270889\n",
            "MarkDown2       310322\n",
            "MarkDown3       284479\n",
            "MarkDown4       286603\n",
            "MarkDown5       270138\n",
            "CPI                  0\n",
            "Unemployment         0\n",
            "dtype: int64\n",
            "\n",
            "--- Verificando NaNs em df_test_merged ANTES do tratamento ---\n",
            "Store               0\n",
            "Dept                0\n",
            "Date                0\n",
            "IsHoliday           0\n",
            "Type                0\n",
            "Size                0\n",
            "Temperature         0\n",
            "Fuel_Price          0\n",
            "MarkDown1         149\n",
            "MarkDown2       28627\n",
            "MarkDown3        9829\n",
            "MarkDown4       12888\n",
            "MarkDown5           0\n",
            "CPI             38162\n",
            "Unemployment    38162\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Verificando NaNs em df_train_merged ANTES do tratamento ---\")\n",
        "print(df_train_merged.isnull().sum())\n",
        "\n",
        "print(\"\\n--- Verificando NaNs em df_test_merged ANTES do tratamento ---\")\n",
        "print(df_test_merged.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOEZ2--FrVSp"
      },
      "source": [
        "Tratamento de NaNs nas colunas MarkDown1 a MarkDown5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f6tyjYLrUaf",
        "outputId": "c7b411e9-9699-4d44-8ed5-dcef421ed8f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Tratando NaNs nas colunas MarkDown (preenchendo com 0) ---\n",
            "Preenchimento de NaNs nas colunas MarkDown concluído.\n",
            "\n",
            "--- Tratando NaNs em CPI e Unemployment (ffill e bfill por Loja) ---\n",
            "Tratando df_train_merged para CPI e Unemployment...\n",
            "Tratando df_test_merged para CPI e Unemployment...\n",
            "Preenchimento de NaNs em CPI e Unemployment concluído.\n",
            "\n",
            "--- Verificando NaNs em df_train_merged APÓS o tratamento ---\n",
            "Store           0\n",
            "Dept            0\n",
            "Date            0\n",
            "Weekly_Sales    0\n",
            "IsHoliday       0\n",
            "Type            0\n",
            "Size            0\n",
            "Temperature     0\n",
            "Fuel_Price      0\n",
            "MarkDown1       0\n",
            "MarkDown2       0\n",
            "MarkDown3       0\n",
            "MarkDown4       0\n",
            "MarkDown5       0\n",
            "CPI             0\n",
            "Unemployment    0\n",
            "dtype: int64\n",
            "\n",
            "--- Verificando NaNs em df_test_merged APÓS o tratamento ---\n",
            "Store           0\n",
            "Dept            0\n",
            "Date            0\n",
            "IsHoliday       0\n",
            "Type            0\n",
            "Size            0\n",
            "Temperature     0\n",
            "Fuel_Price      0\n",
            "MarkDown1       0\n",
            "MarkDown2       0\n",
            "MarkDown3       0\n",
            "MarkDown4       0\n",
            "MarkDown5       0\n",
            "CPI             0\n",
            "Unemployment    0\n",
            "dtype: int64\n",
            "\n",
            "Tratamento de valores ausentes (NaNs) concluído!\n"
          ]
        }
      ],
      "source": [
        "# 1. Tratamento de NaNs nas colunas MarkDown1 a MarkDown5\n",
        "# Estratégia: Preencher NaNs com 0, pois indicam ausência de promoção.\n",
        "markdown_cols = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\n",
        "\n",
        "print(\"\\n--- Tratando NaNs nas colunas MarkDown (preenchendo com 0) ---\")\n",
        "for col in markdown_cols:\n",
        "    if col in df_train_merged.columns:\n",
        "        df_train_merged[col] = df_train_merged[col].fillna(0)\n",
        "    if col in df_test_merged.columns:\n",
        "        df_test_merged[col] = df_test_merged[col].fillna(0)\n",
        "print(\"Preenchimento de NaNs nas colunas MarkDown concluído.\")\n",
        "\n",
        "# 2. Tratamento de NaNs nas colunas CPI e Unemployment\n",
        "# Estratégia: Preenchimento progressivo (ffill) e depois regressivo (bfill), agrupado por 'Store'.\n",
        "cols_to_ffill_bfill = ['CPI', 'Unemployment']\n",
        "\n",
        "print(\"\\n--- Tratando NaNs em CPI e Unemployment (ffill e bfill por Loja) ---\")\n",
        "\n",
        "# Para df_train_merged\n",
        "print(\"Tratando df_train_merged para CPI e Unemployment...\")\n",
        "for col in cols_to_ffill_bfill:\n",
        "    if col in df_train_merged.columns:\n",
        "        # Agrupa por 'Store', aplica ffill e depois bfill dentro de cada grupo\n",
        "        df_train_merged[col] = df_train_merged.groupby('Store')[col].ffill()\n",
        "        df_train_merged[col] = df_train_merged.groupby('Store')[col].bfill()\n",
        "    else:\n",
        "        print(f\"Coluna {col} não encontrada em df_train_merged.\")\n",
        "\n",
        "# Para df_test_merged\n",
        "print(\"Tratando df_test_merged para CPI e Unemployment...\")\n",
        "for col in cols_to_ffill_bfill:\n",
        "    if col in df_test_merged.columns:\n",
        "        # Agrupa por 'Store', aplica ffill e depois bfill dentro de cada grupo\n",
        "        df_test_merged[col] = df_test_merged.groupby('Store')[col].ffill()\n",
        "        df_test_merged[col] = df_test_merged.groupby('Store')[col].bfill()\n",
        "    else:\n",
        "        print(f\"Coluna {col} não encontrada em df_test_merged.\")\n",
        "print(\"Preenchimento de NaNs em CPI e Unemployment concluído.\")\n",
        "\n",
        "# 3. Verificação final de NaNs\n",
        "print(\"\\n--- Verificando NaNs em df_train_merged APÓS o tratamento ---\")\n",
        "print(df_train_merged.isnull().sum())\n",
        "\n",
        "print(\"\\n--- Verificando NaNs em df_test_merged APÓS o tratamento ---\")\n",
        "print(df_test_merged.isnull().sum())\n",
        "\n",
        "print(\"\\nTratamento de valores ausentes (NaNs) concluído!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGhtBZZut1k8"
      },
      "source": [
        "## Transformação de Variáveis Categóricas (One-Hot Encoding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw_X0knEuBWM"
      },
      "source": [
        "### Alteração de colunas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "oJjiYvARt1Sj",
        "outputId": "525f1eb7-82fe-493a-fd79-c077ae8b23ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Transformando a coluna 'Type' (One-Hot Encoding) ---\n",
            "Coluna 'Type' transformada em df_train_merged.\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Store",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Dept",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Date",
                  "rawType": "datetime64[ns]",
                  "type": "datetime"
                },
                {
                  "name": "Weekly_Sales",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "IsHoliday",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Size",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Temperature",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_Price",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown2",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown3",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown4",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown5",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "CPI",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Unemployment",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Type_A",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Type_B",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Type_C",
                  "rawType": "bool",
                  "type": "boolean"
                }
              ],
              "ref": "761b6f1c-e7d2-4835-9a45-4bf881eebe5b",
              "rows": [
                [
                  "0",
                  "1",
                  "1",
                  "2010-02-05 00:00:00",
                  "24924.5",
                  "False",
                  "151315",
                  "42.31",
                  "2.572",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "211.0963582",
                  "8.106",
                  "True",
                  "False",
                  "False"
                ],
                [
                  "1",
                  "1",
                  "1",
                  "2010-02-12 00:00:00",
                  "46039.49",
                  "True",
                  "151315",
                  "38.51",
                  "2.548",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "211.2421698",
                  "8.106",
                  "True",
                  "False",
                  "False"
                ]
              ],
              "shape": {
                "columns": 18,
                "rows": 2
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Dept</th>\n",
              "      <th>Date</th>\n",
              "      <th>Weekly_Sales</th>\n",
              "      <th>IsHoliday</th>\n",
              "      <th>Size</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Fuel_Price</th>\n",
              "      <th>MarkDown1</th>\n",
              "      <th>MarkDown2</th>\n",
              "      <th>MarkDown3</th>\n",
              "      <th>MarkDown4</th>\n",
              "      <th>MarkDown5</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Unemployment</th>\n",
              "      <th>Type_A</th>\n",
              "      <th>Type_B</th>\n",
              "      <th>Type_C</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>24924.50</td>\n",
              "      <td>False</td>\n",
              "      <td>151315</td>\n",
              "      <td>42.31</td>\n",
              "      <td>2.572</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>211.096358</td>\n",
              "      <td>8.106</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-12</td>\n",
              "      <td>46039.49</td>\n",
              "      <td>True</td>\n",
              "      <td>151315</td>\n",
              "      <td>38.51</td>\n",
              "      <td>2.548</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>211.242170</td>\n",
              "      <td>8.106</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Store  Dept       Date  Weekly_Sales  IsHoliday    Size  Temperature  \\\n",
              "0      1     1 2010-02-05      24924.50      False  151315        42.31   \n",
              "1      1     1 2010-02-12      46039.49       True  151315        38.51   \n",
              "\n",
              "   Fuel_Price  MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5  \\\n",
              "0       2.572        0.0        0.0        0.0        0.0        0.0   \n",
              "1       2.548        0.0        0.0        0.0        0.0        0.0   \n",
              "\n",
              "          CPI  Unemployment  Type_A  Type_B  Type_C  \n",
              "0  211.096358         8.106    True   False   False  \n",
              "1  211.242170         8.106    True   False   False  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Coluna 'Type' transformada em df_test_merged.\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Store",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Dept",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Date",
                  "rawType": "datetime64[ns]",
                  "type": "datetime"
                },
                {
                  "name": "IsHoliday",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Size",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Temperature",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_Price",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown2",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown3",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown4",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "MarkDown5",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "CPI",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Unemployment",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Type_A",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Type_B",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "Type_C",
                  "rawType": "bool",
                  "type": "boolean"
                }
              ],
              "ref": "25404137-b60c-4906-a85b-d98d5e33a699",
              "rows": [
                [
                  "0",
                  "1",
                  "1",
                  "2012-11-02 00:00:00",
                  "False",
                  "151315",
                  "55.32",
                  "3.386",
                  "6766.44",
                  "5147.7",
                  "50.82",
                  "3639.9",
                  "2737.42",
                  "223.4627793",
                  "6.573",
                  "True",
                  "False",
                  "False"
                ],
                [
                  "1",
                  "1",
                  "1",
                  "2012-11-09 00:00:00",
                  "False",
                  "151315",
                  "61.24",
                  "3.314",
                  "11421.32",
                  "3370.89",
                  "40.28",
                  "4646.79",
                  "6154.16",
                  "223.4813073",
                  "6.573",
                  "True",
                  "False",
                  "False"
                ]
              ],
              "shape": {
                "columns": 17,
                "rows": 2
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Dept</th>\n",
              "      <th>Date</th>\n",
              "      <th>IsHoliday</th>\n",
              "      <th>Size</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Fuel_Price</th>\n",
              "      <th>MarkDown1</th>\n",
              "      <th>MarkDown2</th>\n",
              "      <th>MarkDown3</th>\n",
              "      <th>MarkDown4</th>\n",
              "      <th>MarkDown5</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Unemployment</th>\n",
              "      <th>Type_A</th>\n",
              "      <th>Type_B</th>\n",
              "      <th>Type_C</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2012-11-02</td>\n",
              "      <td>False</td>\n",
              "      <td>151315</td>\n",
              "      <td>55.32</td>\n",
              "      <td>3.386</td>\n",
              "      <td>6766.44</td>\n",
              "      <td>5147.70</td>\n",
              "      <td>50.82</td>\n",
              "      <td>3639.90</td>\n",
              "      <td>2737.42</td>\n",
              "      <td>223.462779</td>\n",
              "      <td>6.573</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2012-11-09</td>\n",
              "      <td>False</td>\n",
              "      <td>151315</td>\n",
              "      <td>61.24</td>\n",
              "      <td>3.314</td>\n",
              "      <td>11421.32</td>\n",
              "      <td>3370.89</td>\n",
              "      <td>40.28</td>\n",
              "      <td>4646.79</td>\n",
              "      <td>6154.16</td>\n",
              "      <td>223.481307</td>\n",
              "      <td>6.573</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Store  Dept       Date  IsHoliday    Size  Temperature  Fuel_Price  \\\n",
              "0      1     1 2012-11-02      False  151315        55.32       3.386   \n",
              "1      1     1 2012-11-09      False  151315        61.24       3.314   \n",
              "\n",
              "   MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5         CPI  \\\n",
              "0    6766.44    5147.70      50.82    3639.90    2737.42  223.462779   \n",
              "1   11421.32    3370.89      40.28    4646.79    6154.16  223.481307   \n",
              "\n",
              "   Unemployment  Type_A  Type_B  Type_C  \n",
              "0         6.573    True   False   False  \n",
              "1         6.573    True   False   False  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"--- Transformando a coluna 'Type' (One-Hot Encoding) ---\")\n",
        "\n",
        "# Aplicar em df_train_merged\n",
        "df_train_merged = pd.get_dummies(df_train_merged, columns=['Type'], prefix='Type')\n",
        "print(\"Coluna 'Type' transformada em df_train_merged.\")\n",
        "display(df_train_merged.head(2)) # Mostrar algumas linhas para ver as novas colunas\n",
        "\n",
        "# Aplicar em df_test_merged\n",
        "df_test_merged = pd.get_dummies(df_test_merged, columns=['Type'], prefix='Type')\n",
        "print(\"\\nColuna 'Type' transformada em df_test_merged.\")\n",
        "display(df_test_merged.head(2)) # Mostrar algumas linhas para ver as novas colunas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1eijM-quh-Z"
      },
      "source": [
        "Transformação da Variável Booleana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "7heSep_DuiSf",
        "outputId": "7fb6a99f-8e73-4647-c40b-4a7a2cc05ab2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Transformando a coluna 'IsHoliday' para int (0/1) ---\n",
            "Coluna 'IsHoliday' transformada para int em df_train_merged.\n",
            "Coluna 'IsHoliday' transformada para int em df_test_merged.\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Date",
                  "rawType": "datetime64[ns]",
                  "type": "datetime"
                },
                {
                  "name": "IsHoliday",
                  "rawType": "int32",
                  "type": "integer"
                }
              ],
              "ref": "a9b075f1-0588-4e44-a09f-9b003e1c1331",
              "rows": [
                [
                  "0",
                  "2010-02-05 00:00:00",
                  "0"
                ],
                [
                  "1",
                  "2010-02-12 00:00:00",
                  "1"
                ],
                [
                  "2",
                  "2010-02-19 00:00:00",
                  "0"
                ]
              ],
              "shape": {
                "columns": 2,
                "rows": 3
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>IsHoliday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-02-12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-02-19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date  IsHoliday\n",
              "0 2010-02-05          0\n",
              "1 2010-02-12          1\n",
              "2 2010-02-19          0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"\\n--- Transformando a coluna 'IsHoliday' para int (0/1) ---\")\n",
        "\n",
        "# Aplicar em df_train_merged\n",
        "df_train_merged['IsHoliday'] = df_train_merged['IsHoliday'].astype(int)\n",
        "print(\"Coluna 'IsHoliday' transformada para int em df_train_merged.\")\n",
        "\n",
        "# Aplicar em df_test_merged\n",
        "df_test_merged['IsHoliday'] = df_test_merged['IsHoliday'].astype(int)\n",
        "print(\"Coluna 'IsHoliday' transformada para int em df_test_merged.\")\n",
        "\n",
        "display(df_train_merged[['Date', 'IsHoliday']].head(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMkGjJT7u9Wb"
      },
      "source": [
        "# Engenharia de Features\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBmhgp3J0C5z"
      },
      "source": [
        "## Criação de Features Temporais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "7Zus_g0QvBFS",
        "outputId": "63e17cf9-a3a8-4843-c88f-9bcee9d38095"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Criando Features Temporais ---\n",
            "Features temporais criadas em df_train_merged e df_test_merged.\n",
            "\n",
            "Exemplo de features temporais em df_train_merged:\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Date",
                  "rawType": "datetime64[ns]",
                  "type": "datetime"
                },
                {
                  "name": "Year",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "Month",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "Day",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "WeekOfYear",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "DayOfWeek",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "DayOfYear",
                  "rawType": "int32",
                  "type": "integer"
                }
              ],
              "ref": "140c2673-d23d-48e2-a6b7-b8141842d8cb",
              "rows": [
                [
                  "0",
                  "2010-02-05 00:00:00",
                  "2010",
                  "2",
                  "5",
                  "5",
                  "4",
                  "36"
                ],
                [
                  "1",
                  "2010-02-12 00:00:00",
                  "2010",
                  "2",
                  "12",
                  "6",
                  "4",
                  "43"
                ],
                [
                  "2",
                  "2010-02-19 00:00:00",
                  "2010",
                  "2",
                  "19",
                  "7",
                  "4",
                  "50"
                ],
                [
                  "3",
                  "2010-02-26 00:00:00",
                  "2010",
                  "2",
                  "26",
                  "8",
                  "4",
                  "57"
                ],
                [
                  "4",
                  "2010-03-05 00:00:00",
                  "2010",
                  "3",
                  "5",
                  "9",
                  "4",
                  "64"
                ]
              ],
              "shape": {
                "columns": 7,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>WeekOfYear</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>DayOfYear</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>2010</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-02-12</td>\n",
              "      <td>2010</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-02-19</td>\n",
              "      <td>2010</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-02-26</td>\n",
              "      <td>2010</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-03-05</td>\n",
              "      <td>2010</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date  Year  Month  Day  WeekOfYear  DayOfWeek  DayOfYear\n",
              "0 2010-02-05  2010      2    5           5          4         36\n",
              "1 2010-02-12  2010      2   12           6          4         43\n",
              "2 2010-02-19  2010      2   19           7          4         50\n",
              "3 2010-02-26  2010      2   26           8          4         57\n",
              "4 2010-03-05  2010      3    5           9          4         64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Exemplo de features temporais em df_test_merged:\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Date",
                  "rawType": "datetime64[ns]",
                  "type": "datetime"
                },
                {
                  "name": "Year",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "Month",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "Day",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "WeekOfYear",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "DayOfWeek",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "DayOfYear",
                  "rawType": "int32",
                  "type": "integer"
                }
              ],
              "ref": "174a6ea6-eea5-46bf-9993-04fa1b5e460d",
              "rows": [
                [
                  "0",
                  "2012-11-02 00:00:00",
                  "2012",
                  "11",
                  "2",
                  "44",
                  "4",
                  "307"
                ],
                [
                  "1",
                  "2012-11-09 00:00:00",
                  "2012",
                  "11",
                  "9",
                  "45",
                  "4",
                  "314"
                ],
                [
                  "2",
                  "2012-11-16 00:00:00",
                  "2012",
                  "11",
                  "16",
                  "46",
                  "4",
                  "321"
                ],
                [
                  "3",
                  "2012-11-23 00:00:00",
                  "2012",
                  "11",
                  "23",
                  "47",
                  "4",
                  "328"
                ],
                [
                  "4",
                  "2012-11-30 00:00:00",
                  "2012",
                  "11",
                  "30",
                  "48",
                  "4",
                  "335"
                ]
              ],
              "shape": {
                "columns": 7,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>WeekOfYear</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>DayOfYear</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-11-02</td>\n",
              "      <td>2012</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>44</td>\n",
              "      <td>4</td>\n",
              "      <td>307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-11-09</td>\n",
              "      <td>2012</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>45</td>\n",
              "      <td>4</td>\n",
              "      <td>314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-11-16</td>\n",
              "      <td>2012</td>\n",
              "      <td>11</td>\n",
              "      <td>16</td>\n",
              "      <td>46</td>\n",
              "      <td>4</td>\n",
              "      <td>321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-11-23</td>\n",
              "      <td>2012</td>\n",
              "      <td>11</td>\n",
              "      <td>23</td>\n",
              "      <td>47</td>\n",
              "      <td>4</td>\n",
              "      <td>328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-11-30</td>\n",
              "      <td>2012</td>\n",
              "      <td>11</td>\n",
              "      <td>30</td>\n",
              "      <td>48</td>\n",
              "      <td>4</td>\n",
              "      <td>335</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date  Year  Month  Day  WeekOfYear  DayOfWeek  DayOfYear\n",
              "0 2012-11-02  2012     11    2          44          4        307\n",
              "1 2012-11-09  2012     11    9          45          4        314\n",
              "2 2012-11-16  2012     11   16          46          4        321\n",
              "3 2012-11-23  2012     11   23          47          4        328\n",
              "4 2012-11-30  2012     11   30          48          4        335"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"--- Criando Features Temporais ---\")\n",
        "\n",
        "def criar_features_temporais(df):\n",
        "    df_copy = df.copy() # Trabalhar em uma cópia para evitar SettingWithCopyWarning\n",
        "    df_copy['Year'] = df_copy['Date'].dt.year\n",
        "    df_copy['Month'] = df_copy['Date'].dt.month\n",
        "    df_copy['Day'] = df_copy['Date'].dt.day\n",
        "    df_copy['WeekOfYear'] = df_copy['Date'].dt.isocalendar().week.astype(int) # Semana do ano (ISO)\n",
        "    df_copy['DayOfWeek'] = df_copy['Date'].dt.dayofweek # Segunda=0, Domingo=6\n",
        "    df_copy['DayOfYear'] = df_copy['Date'].dt.dayofyear\n",
        "    # Adicionar mais features se desejar:\n",
        "    # df_copy['Quarter'] = df_copy['Date'].dt.quarter\n",
        "    # df_copy['IsMonthStart'] = df_copy['Date'].dt.is_month_start.astype(int)\n",
        "    # df_copy['IsMonthEnd'] = df_copy['Date'].dt.is_month_end.astype(int)\n",
        "    # df_copy['IsYearStart'] = df_copy['Date'].dt.is_year_start.astype(int)\n",
        "    # df_copy['IsYearEnd'] = df_copy['Date'].dt.is_year_end.astype(int)\n",
        "    return df_copy\n",
        "\n",
        "# Aplicar a função aos dataframes\n",
        "df_train_merged = criar_features_temporais(df_train_merged)\n",
        "df_test_merged = criar_features_temporais(df_test_merged)\n",
        "\n",
        "print(\"Features temporais criadas em df_train_merged e df_test_merged.\")\n",
        "\n",
        "# Verificar as novas colunas em df_train_merged\n",
        "print(\"\\nExemplo de features temporais em df_train_merged:\")\n",
        "display(df_train_merged[['Date', 'Year', 'Month', 'Day', 'WeekOfYear', 'DayOfWeek', 'DayOfYear']].head())\n",
        "\n",
        "# Verificar as novas colunas em df_test_merged\n",
        "print(\"\\nExemplo de features temporais em df_test_merged:\")\n",
        "display(df_test_merged[['Date', 'Year', 'Month', 'Day', 'WeekOfYear', 'DayOfWeek', 'DayOfYear']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hzyM8VlgaiU"
      },
      "source": [
        "## Criação de Features de Lag (Defasagem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aJVRVfLlvBgP",
        "outputId": "440077e8-66e5-4040-e5b1-d47dc6a96dc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Criando Features de Lag (com ajuste para FutureWarning) ---\n",
            "Features de lag [1, 2, 3, 4, 12, 26, 52] criadas no dataframe combinado.\n",
            "Features de lag adicionadas a df_train_merged e df_test_merged.\n",
            "\n",
            "Exemplo de features de lag em df_train_merged (Loja 1, Dept 1):\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Date",
                  "rawType": "datetime64[ns]",
                  "type": "datetime"
                },
                {
                  "name": "Weekly_Sales",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Weekly_Sales_lag_1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Weekly_Sales_lag_2",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Weekly_Sales_lag_3",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Weekly_Sales_lag_4",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Weekly_Sales_lag_12",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Weekly_Sales_lag_26",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Weekly_Sales_lag_52",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "63c40f86-3051-4ff9-b2b2-959595cbfc3f",
              "rows": [
                [
                  "0",
                  "2010-02-05 00:00:00",
                  "24924.5",
                  null,
                  null,
                  null,
                  null,
                  null,
                  null,
                  null
                ],
                [
                  "1",
                  "2010-02-12 00:00:00",
                  "46039.49",
                  "24924.5",
                  null,
                  null,
                  null,
                  null,
                  null,
                  null
                ],
                [
                  "2",
                  "2010-02-19 00:00:00",
                  "41595.55",
                  "46039.49",
                  "24924.5",
                  null,
                  null,
                  null,
                  null,
                  null
                ],
                [
                  "3",
                  "2010-02-26 00:00:00",
                  "19403.54",
                  "41595.55",
                  "46039.49",
                  "24924.5",
                  null,
                  null,
                  null,
                  null
                ],
                [
                  "4",
                  "2010-03-05 00:00:00",
                  "21827.9",
                  "19403.54",
                  "41595.55",
                  "46039.49",
                  "24924.5",
                  null,
                  null,
                  null
                ],
                [
                  "5",
                  "2010-03-12 00:00:00",
                  "21043.39",
                  "21827.9",
                  "19403.54",
                  "41595.55",
                  "46039.49",
                  null,
                  null,
                  null
                ],
                [
                  "6",
                  "2010-03-19 00:00:00",
                  "22136.64",
                  "21043.39",
                  "21827.9",
                  "19403.54",
                  "41595.55",
                  null,
                  null,
                  null
                ],
                [
                  "7",
                  "2010-03-26 00:00:00",
                  "26229.21",
                  "22136.64",
                  "21043.39",
                  "21827.9",
                  "19403.54",
                  null,
                  null,
                  null
                ],
                [
                  "8",
                  "2010-04-02 00:00:00",
                  "57258.43",
                  "26229.21",
                  "22136.64",
                  "21043.39",
                  "21827.9",
                  null,
                  null,
                  null
                ],
                [
                  "9",
                  "2010-04-09 00:00:00",
                  "42960.91",
                  "57258.43",
                  "26229.21",
                  "22136.64",
                  "21043.39",
                  null,
                  null,
                  null
                ]
              ],
              "shape": {
                "columns": 9,
                "rows": 10
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Weekly_Sales</th>\n",
              "      <th>Weekly_Sales_lag_1</th>\n",
              "      <th>Weekly_Sales_lag_2</th>\n",
              "      <th>Weekly_Sales_lag_3</th>\n",
              "      <th>Weekly_Sales_lag_4</th>\n",
              "      <th>Weekly_Sales_lag_12</th>\n",
              "      <th>Weekly_Sales_lag_26</th>\n",
              "      <th>Weekly_Sales_lag_52</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>24924.50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-02-12</td>\n",
              "      <td>46039.49</td>\n",
              "      <td>24924.50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-02-19</td>\n",
              "      <td>41595.55</td>\n",
              "      <td>46039.49</td>\n",
              "      <td>24924.50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-02-26</td>\n",
              "      <td>19403.54</td>\n",
              "      <td>41595.55</td>\n",
              "      <td>46039.49</td>\n",
              "      <td>24924.50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-03-05</td>\n",
              "      <td>21827.90</td>\n",
              "      <td>19403.54</td>\n",
              "      <td>41595.55</td>\n",
              "      <td>46039.49</td>\n",
              "      <td>24924.50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2010-03-12</td>\n",
              "      <td>21043.39</td>\n",
              "      <td>21827.90</td>\n",
              "      <td>19403.54</td>\n",
              "      <td>41595.55</td>\n",
              "      <td>46039.49</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2010-03-19</td>\n",
              "      <td>22136.64</td>\n",
              "      <td>21043.39</td>\n",
              "      <td>21827.90</td>\n",
              "      <td>19403.54</td>\n",
              "      <td>41595.55</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2010-03-26</td>\n",
              "      <td>26229.21</td>\n",
              "      <td>22136.64</td>\n",
              "      <td>21043.39</td>\n",
              "      <td>21827.90</td>\n",
              "      <td>19403.54</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2010-04-02</td>\n",
              "      <td>57258.43</td>\n",
              "      <td>26229.21</td>\n",
              "      <td>22136.64</td>\n",
              "      <td>21043.39</td>\n",
              "      <td>21827.90</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2010-04-09</td>\n",
              "      <td>42960.91</td>\n",
              "      <td>57258.43</td>\n",
              "      <td>26229.21</td>\n",
              "      <td>22136.64</td>\n",
              "      <td>21043.39</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date  Weekly_Sales  Weekly_Sales_lag_1  Weekly_Sales_lag_2  \\\n",
              "0 2010-02-05      24924.50                 NaN                 NaN   \n",
              "1 2010-02-12      46039.49            24924.50                 NaN   \n",
              "2 2010-02-19      41595.55            46039.49            24924.50   \n",
              "3 2010-02-26      19403.54            41595.55            46039.49   \n",
              "4 2010-03-05      21827.90            19403.54            41595.55   \n",
              "5 2010-03-12      21043.39            21827.90            19403.54   \n",
              "6 2010-03-19      22136.64            21043.39            21827.90   \n",
              "7 2010-03-26      26229.21            22136.64            21043.39   \n",
              "8 2010-04-02      57258.43            26229.21            22136.64   \n",
              "9 2010-04-09      42960.91            57258.43            26229.21   \n",
              "\n",
              "   Weekly_Sales_lag_3  Weekly_Sales_lag_4  Weekly_Sales_lag_12  \\\n",
              "0                 NaN                 NaN                  NaN   \n",
              "1                 NaN                 NaN                  NaN   \n",
              "2                 NaN                 NaN                  NaN   \n",
              "3            24924.50                 NaN                  NaN   \n",
              "4            46039.49            24924.50                  NaN   \n",
              "5            41595.55            46039.49                  NaN   \n",
              "6            19403.54            41595.55                  NaN   \n",
              "7            21827.90            19403.54                  NaN   \n",
              "8            21043.39            21827.90                  NaN   \n",
              "9            22136.64            21043.39                  NaN   \n",
              "\n",
              "   Weekly_Sales_lag_26  Weekly_Sales_lag_52  \n",
              "0                  NaN                  NaN  \n",
              "1                  NaN                  NaN  \n",
              "2                  NaN                  NaN  \n",
              "3                  NaN                  NaN  \n",
              "4                  NaN                  NaN  \n",
              "5                  NaN                  NaN  \n",
              "6                  NaN                  NaN  \n",
              "7                  NaN                  NaN  \n",
              "8                  NaN                  NaN  \n",
              "9                  NaN                  NaN  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Exemplo de features de lag em df_test_merged (Loja 1, Dept 1):\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Date",
                  "rawType": "datetime64[ns]",
                  "type": "datetime"
                },
                {
                  "name": "Weekly_Sales_lag_1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Weekly_Sales_lag_2",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Weekly_Sales_lag_3",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Weekly_Sales_lag_4",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Weekly_Sales_lag_12",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Weekly_Sales_lag_26",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Weekly_Sales_lag_52",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "2be753b1-e95b-4e8b-b450-8e45f1f523db",
              "rows": [
                [
                  "0",
                  "2012-11-02 00:00:00",
                  "27390.81",
                  "24185.27",
                  "22764.01",
                  "21904.47",
                  "16119.92",
                  "17147.44",
                  "39886.06"
                ],
                [
                  "1",
                  "2012-11-09 00:00:00",
                  null,
                  "27390.81",
                  "24185.27",
                  "22764.01",
                  "17330.7",
                  "18164.2",
                  "18689.54"
                ],
                [
                  "2",
                  "2012-11-16 00:00:00",
                  null,
                  null,
                  "27390.81",
                  "24185.27",
                  "16286.4",
                  "18517.79",
                  "19050.66"
                ],
                [
                  "3",
                  "2012-11-23 00:00:00",
                  null,
                  null,
                  null,
                  "27390.81",
                  "16680.24",
                  "16963.55",
                  "20911.25"
                ],
                [
                  "4",
                  "2012-11-30 00:00:00",
                  null,
                  null,
                  null,
                  null,
                  "18322.37",
                  "16065.49",
                  "25293.49"
                ],
                [
                  "5",
                  "2012-12-07 00:00:00",
                  null,
                  null,
                  null,
                  null,
                  "19616.22",
                  "17666.0",
                  "33305.92"
                ],
                [
                  "6",
                  "2012-12-14 00:00:00",
                  null,
                  null,
                  null,
                  null,
                  "19251.5",
                  "17558.82",
                  "45773.03"
                ],
                [
                  "7",
                  "2012-12-21 00:00:00",
                  null,
                  null,
                  null,
                  null,
                  "18947.81",
                  "16633.41",
                  "46788.75"
                ],
                [
                  "8",
                  "2012-12-28 00:00:00",
                  null,
                  null,
                  null,
                  null,
                  "21904.47",
                  "15722.82",
                  "23350.88"
                ],
                [
                  "9",
                  "2013-01-04 00:00:00",
                  null,
                  null,
                  null,
                  null,
                  "22764.01",
                  "17823.37",
                  "16567.69"
                ]
              ],
              "shape": {
                "columns": 8,
                "rows": 10
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Weekly_Sales_lag_1</th>\n",
              "      <th>Weekly_Sales_lag_2</th>\n",
              "      <th>Weekly_Sales_lag_3</th>\n",
              "      <th>Weekly_Sales_lag_4</th>\n",
              "      <th>Weekly_Sales_lag_12</th>\n",
              "      <th>Weekly_Sales_lag_26</th>\n",
              "      <th>Weekly_Sales_lag_52</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-11-02</td>\n",
              "      <td>27390.81</td>\n",
              "      <td>24185.27</td>\n",
              "      <td>22764.01</td>\n",
              "      <td>21904.47</td>\n",
              "      <td>16119.92</td>\n",
              "      <td>17147.44</td>\n",
              "      <td>39886.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-11-09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>27390.81</td>\n",
              "      <td>24185.27</td>\n",
              "      <td>22764.01</td>\n",
              "      <td>17330.70</td>\n",
              "      <td>18164.20</td>\n",
              "      <td>18689.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-11-16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>27390.81</td>\n",
              "      <td>24185.27</td>\n",
              "      <td>16286.40</td>\n",
              "      <td>18517.79</td>\n",
              "      <td>19050.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-11-23</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>27390.81</td>\n",
              "      <td>16680.24</td>\n",
              "      <td>16963.55</td>\n",
              "      <td>20911.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-11-30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18322.37</td>\n",
              "      <td>16065.49</td>\n",
              "      <td>25293.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2012-12-07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19616.22</td>\n",
              "      <td>17666.00</td>\n",
              "      <td>33305.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2012-12-14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19251.50</td>\n",
              "      <td>17558.82</td>\n",
              "      <td>45773.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2012-12-21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18947.81</td>\n",
              "      <td>16633.41</td>\n",
              "      <td>46788.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2012-12-28</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21904.47</td>\n",
              "      <td>15722.82</td>\n",
              "      <td>23350.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2013-01-04</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22764.01</td>\n",
              "      <td>17823.37</td>\n",
              "      <td>16567.69</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date  Weekly_Sales_lag_1  Weekly_Sales_lag_2  Weekly_Sales_lag_3  \\\n",
              "0 2012-11-02            27390.81            24185.27            22764.01   \n",
              "1 2012-11-09                 NaN            27390.81            24185.27   \n",
              "2 2012-11-16                 NaN                 NaN            27390.81   \n",
              "3 2012-11-23                 NaN                 NaN                 NaN   \n",
              "4 2012-11-30                 NaN                 NaN                 NaN   \n",
              "5 2012-12-07                 NaN                 NaN                 NaN   \n",
              "6 2012-12-14                 NaN                 NaN                 NaN   \n",
              "7 2012-12-21                 NaN                 NaN                 NaN   \n",
              "8 2012-12-28                 NaN                 NaN                 NaN   \n",
              "9 2013-01-04                 NaN                 NaN                 NaN   \n",
              "\n",
              "   Weekly_Sales_lag_4  Weekly_Sales_lag_12  Weekly_Sales_lag_26  \\\n",
              "0            21904.47             16119.92             17147.44   \n",
              "1            22764.01             17330.70             18164.20   \n",
              "2            24185.27             16286.40             18517.79   \n",
              "3            27390.81             16680.24             16963.55   \n",
              "4                 NaN             18322.37             16065.49   \n",
              "5                 NaN             19616.22             17666.00   \n",
              "6                 NaN             19251.50             17558.82   \n",
              "7                 NaN             18947.81             16633.41   \n",
              "8                 NaN             21904.47             15722.82   \n",
              "9                 NaN             22764.01             17823.37   \n",
              "\n",
              "   Weekly_Sales_lag_52  \n",
              "0             39886.06  \n",
              "1             18689.54  \n",
              "2             19050.66  \n",
              "3             20911.25  \n",
              "4             25293.49  \n",
              "5             33305.92  \n",
              "6             45773.03  \n",
              "7             46788.75  \n",
              "8             23350.88  \n",
              "9             16567.69  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Verificando NaNs introduzidos pelos lags em df_train_merged:\n",
            "Weekly_Sales_lag_52    160487\n",
            "Weekly_Sales_lag_26     81918\n",
            "Weekly_Sales_lag_12     38615\n",
            "Weekly_Sales_lag_4      13134\n",
            "Weekly_Sales_lag_3       9889\n",
            "Weekly_Sales_lag_2       6625\n",
            "Weekly_Sales_lag_1       3331\n",
            "dtype: int64\n",
            "\n",
            "Verificando NaNs introduzidos pelos lags em df_test_merged:\n",
            "Weekly_Sales_lag_1     111906\n",
            "Weekly_Sales_lag_2     108793\n",
            "Weekly_Sales_lag_3     105706\n",
            "Weekly_Sales_lag_4     102641\n",
            "Weekly_Sales_lag_12     78564\n",
            "Weekly_Sales_lag_26     37468\n",
            "Weekly_Sales_lag_52      1346\n",
            "dtype: int64\n",
            "\n",
            "Criação de features de lag concluída!\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Criando Features de Lag (com ajuste para FutureWarning) ---\")\n",
        "\n",
        "# 1. Preparar dataframes temporários para a criação de lags\n",
        "# Selecionar colunas chave e a variável alvo (Weekly_Sales apenas do treino)\n",
        "df_train_temp_for_lag = df_train_merged[['Store', 'Dept', 'Date', 'Weekly_Sales']].copy()\n",
        "df_test_temp_for_lag = df_test_merged[['Store', 'Dept', 'Date']].copy()\n",
        "\n",
        "# Adicionar coluna Weekly_Sales com np.nan para o teste (para consistência de tipo float)\n",
        "df_test_temp_for_lag['Weekly_Sales'] = np.nan #\n",
        "\n",
        "# Adicionar um identificador para separar depois\n",
        "df_train_temp_for_lag['is_train'] = 1\n",
        "df_test_temp_for_lag['is_train'] = 0\n",
        "\n",
        "# 2. Concatenar os dataframes temporários\n",
        "# Este é o ponto onde o FutureWarning ocorria. O ajuste acima com np.nan deve ajudar.\n",
        "df_combined = pd.concat([df_train_temp_for_lag, df_test_temp_for_lag], ignore_index=True)\n",
        "\n",
        "# 3. Ordenar corretamente ANTES de aplicar o shift dentro dos grupos\n",
        "df_combined.sort_values(by=['Store', 'Dept', 'Date'], inplace=True)\n",
        "\n",
        "# 4. Definir os lags que queremos criar\n",
        "lags_to_create = [1, 2, 3, 4, 12, 26, 52] # Ex: 1 semana, 2 sem, ..., 1 ano\n",
        "\n",
        "for lag in lags_to_create:\n",
        "    # O groupby garante que o shift é feito dentro de cada série individual de Loja/Departamento\n",
        "    df_combined[f'Weekly_Sales_lag_{lag}'] = df_combined.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(lag)\n",
        "\n",
        "print(f\"Features de lag {lags_to_create} criadas no dataframe combinado.\")\n",
        "\n",
        "# 5. Separar de volta em treino e teste\n",
        "df_train_with_lags = df_combined[df_combined['is_train'] == 1].copy()\n",
        "df_test_with_lags = df_combined[df_combined['is_train'] == 0].copy()\n",
        "\n",
        "# Remover colunas auxiliares\n",
        "df_train_with_lags.drop(columns=['is_train'], inplace=True)\n",
        "# Para o teste, remover também a coluna 'Weekly_Sales' que foi preenchida com np.nan\n",
        "df_test_with_lags.drop(columns=['is_train', 'Weekly_Sales'], inplace=True)\n",
        "\n",
        "# 6. Juntar as novas colunas de lag de volta aos dataframes originais\n",
        "# Merge para df_train_merged (usando as colunas originais para garantir a junção correta)\n",
        "df_train_merged = pd.merge(\n",
        "    df_train_merged,\n",
        "    df_train_with_lags, # Contém Store, Dept, Date, Weekly_Sales (original) e os lags\n",
        "    on=['Store', 'Dept', 'Date', 'Weekly_Sales'], # Chaves para garantir correspondência exata\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Merge para df_test_merged\n",
        "# No df_test_with_lags, não temos Weekly_Sales (foi removida após ser usada para criar o df_combined),\n",
        "# então o merge será apenas por Store, Dept, Date\n",
        "df_test_merged = pd.merge(\n",
        "    df_test_merged,\n",
        "    df_test_with_lags, # Contém Store, Dept, Date e os lags\n",
        "    on=['Store', 'Dept', 'Date'], # Chaves para o teste\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "print(\"Features de lag adicionadas a df_train_merged e df_test_merged.\")\n",
        "\n",
        "# 7. Verificar as novas colunas e os NaNs introduzidos pelos lags (opcional, mas recomendado)\n",
        "print(\"\\nExemplo de features de lag em df_train_merged (Loja 1, Dept 1):\")\n",
        "cols_to_show_train = ['Date', 'Weekly_Sales'] + [col for col in df_train_merged.columns if 'Weekly_Sales_lag' in col]\n",
        "# Filtrando para uma loja/departamento específico para facilitar a visualização dos lags\n",
        "display(df_train_merged[(df_train_merged['Store']==1) & (df_train_merged['Dept']==1)][cols_to_show_train].head(10))\n",
        "\n",
        "\n",
        "print(\"\\nExemplo de features de lag em df_test_merged (Loja 1, Dept 1):\")\n",
        "cols_to_show_test = ['Date'] + [col for col in df_test_merged.columns if 'Weekly_Sales_lag' in col]\n",
        "display(df_test_merged[(df_test_merged['Store']==1) & (df_test_merged['Dept']==1)][cols_to_show_test].head(10))\n",
        "\n",
        "\n",
        "print(\"\\nVerificando NaNs introduzidos pelos lags em df_train_merged:\")\n",
        "print(df_train_merged[[col for col in df_train_merged.columns if 'Weekly_Sales_lag' in col]].isnull().sum().sort_values(ascending=False))\n",
        "\n",
        "print(\"\\nVerificando NaNs introduzidos pelos lags em df_test_merged:\")\n",
        "print(df_test_merged[[col for col in df_test_merged.columns if 'Weekly_Sales_lag' in col]].isnull().sum().sort_values(ascending=False))\n",
        "\n",
        "print(\"\\nCriação de features de lag concluída!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRDb06mLlR80"
      },
      "source": [
        "## Criação de Features de Janela Móvel (Rolling Window) - V1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M20eWfaBlhfw",
        "outputId": "498348ba-1ff6-4e51-b5cb-3684c3490ca9"
      },
      "outputs": [],
      "source": [
        "# print(\"--- Criando Features de Janela Móvel ---\")\n",
        "\n",
        "# # Definir as janelas e estatísticas que queremos\n",
        "# window_sizes = [4, 8, 12, 26, 52] # Ex: 4 semanas, 8 semanas, etc.\n",
        "# stats_to_calculate = ['mean', 'median', 'sum', 'std'] # Estatísticas a serem calculadas\n",
        "\n",
        "# for window in window_sizes:\n",
        "#     for stat in stats_to_calculate:\n",
        "#         new_col_name = f'Weekly_Sales_roll_{stat}_{window}'\n",
        "#         # Usamos transform para aplicar a função rolling.statistic.shift por grupo\n",
        "#         # A lambda s: s.rolling(...) opera em cada série do grupo\n",
        "#         # O .shift(1) garante que estamos usando apenas dados passados\n",
        "#         df_combined[new_col_name] = df_combined.groupby(['Store', 'Dept'])['Weekly_Sales'].transform(\n",
        "#             lambda s: s.rolling(window=window, min_periods=1).agg(stat).shift(1)\n",
        "#         )\n",
        "#         print(f\"Criada feature: {new_col_name}\")\n",
        "\n",
        "# print(\"Criação de features de janela móvel no df_combined concluída.\")\n",
        "\n",
        "# # 2. Preparar colunas de features de janela móvel para merge\n",
        "# # Selecionar apenas as colunas chave e as novas features de janela móvel\n",
        "# cols_to_merge_rolling = ['Store', 'Dept', 'Date'] + [col for col in df_combined.columns if 'Weekly_Sales_roll_' in col]\n",
        "# df_rolling_features = df_combined[cols_to_merge_rolling].copy()\n",
        "\n",
        "# # 3. Juntar as novas features de janela móvel aos dataframes originais\n",
        "# df_train_merged = pd.merge(df_train_merged, df_rolling_features, on=['Store', 'Dept', 'Date'], how='left')\n",
        "# df_test_merged = pd.merge(df_test_merged, df_rolling_features, on=['Store', 'Dept', 'Date'], how='left')\n",
        "\n",
        "# print(\"Features de janela móvel adicionadas a df_train_merged e df_test_merged.\")\n",
        "\n",
        "# # 4. Verificar as novas colunas e os NaNs introduzidos\n",
        "# print(\"\\nExemplo de features de janela móvel em df_train_merged (Loja 1, Dept 1):\")\n",
        "# cols_to_show_train_roll = ['Date', 'Weekly_Sales'] + [col for col in df_train_merged.columns if 'Weekly_Sales_roll_' in col]\n",
        "# # Filtrando para uma loja/departamento específico\n",
        "# display(df_train_merged[(df_train_merged['Store']==1) & (df_train_merged['Dept']==1)][cols_to_show_train_roll].head(10))\n",
        "\n",
        "# print(\"\\nVerificando NaNs introduzidos pelas features de janela móvel em df_train_merged:\")\n",
        "# print(df_train_merged[[col for col in df_train_merged.columns if 'Weekly_Sales_roll_' in col]].isnull().sum().sort_values(ascending=False))\n",
        "\n",
        "# print(\"\\nVerificando NaNs introduzidos pelas features de janela móvel em df_test_merged:\")\n",
        "# print(df_test_merged[[col for col in df_test_merged.columns if 'Weekly_Sales_roll_' in col]].isnull().sum().sort_values(ascending=False))\n",
        "\n",
        "# print(\"\\nCriação de features de janela móvel concluída!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Criação de Features de Janela Móvel (Rolling Window) - V2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Treino: 2010-02-05 00:00:00 a 2012-07-27 00:00:00 (383040 linhas)\n",
            "Validação: 2012-08-03 00:00:00 a 2012-10-26 00:00:00 (38530 linhas)\n",
            "Teste: 2012-11-02 00:00:00 a 2013-07-26 00:00:00 (115064 linhas)\n",
            "Criada feature no treino: Weekly_Sales_roll_mean_4\n",
            "Criada feature no treino: Weekly_Sales_roll_median_4\n",
            "Criada feature no treino: Weekly_Sales_roll_sum_4\n",
            "Criada feature no treino: Weekly_Sales_roll_std_4\n",
            "Criada feature no treino: Weekly_Sales_roll_mean_8\n",
            "Criada feature no treino: Weekly_Sales_roll_median_8\n",
            "Criada feature no treino: Weekly_Sales_roll_sum_8\n",
            "Criada feature no treino: Weekly_Sales_roll_std_8\n",
            "Criada feature no treino: Weekly_Sales_roll_mean_12\n",
            "Criada feature no treino: Weekly_Sales_roll_median_12\n",
            "Criada feature no treino: Weekly_Sales_roll_sum_12\n",
            "Criada feature no treino: Weekly_Sales_roll_std_12\n",
            "Criada feature no treino: Weekly_Sales_roll_mean_26\n",
            "Criada feature no treino: Weekly_Sales_roll_median_26\n",
            "Criada feature no treino: Weekly_Sales_roll_sum_26\n",
            "Criada feature no treino: Weekly_Sales_roll_std_26\n",
            "Criada feature no treino: Weekly_Sales_roll_mean_52\n",
            "Criada feature no treino: Weekly_Sales_roll_median_52\n",
            "Criada feature no treino: Weekly_Sales_roll_sum_52\n",
            "Criada feature no treino: Weekly_Sales_roll_std_52\n",
            "Criada feature na validação: Weekly_Sales_roll_mean_4\n",
            "Criada feature na validação: Weekly_Sales_roll_median_4\n",
            "Criada feature na validação: Weekly_Sales_roll_sum_4\n",
            "Criada feature na validação: Weekly_Sales_roll_std_4\n",
            "Criada feature na validação: Weekly_Sales_roll_mean_8\n",
            "Criada feature na validação: Weekly_Sales_roll_median_8\n",
            "Criada feature na validação: Weekly_Sales_roll_sum_8\n",
            "Criada feature na validação: Weekly_Sales_roll_std_8\n",
            "Criada feature na validação: Weekly_Sales_roll_mean_12\n",
            "Criada feature na validação: Weekly_Sales_roll_median_12\n",
            "Criada feature na validação: Weekly_Sales_roll_sum_12\n",
            "Criada feature na validação: Weekly_Sales_roll_std_12\n",
            "Criada feature na validação: Weekly_Sales_roll_mean_26\n",
            "Criada feature na validação: Weekly_Sales_roll_median_26\n",
            "Criada feature na validação: Weekly_Sales_roll_sum_26\n",
            "Criada feature na validação: Weekly_Sales_roll_std_26\n",
            "Criada feature na validação: Weekly_Sales_roll_mean_52\n",
            "Criada feature na validação: Weekly_Sales_roll_median_52\n",
            "Criada feature na validação: Weekly_Sales_roll_sum_52\n",
            "Criada feature na validação: Weekly_Sales_roll_std_52\n",
            "Criada feature no teste: Weekly_Sales_roll_mean_4\n",
            "Criada feature no teste: Weekly_Sales_roll_median_4\n",
            "Criada feature no teste: Weekly_Sales_roll_sum_4\n",
            "Criada feature no teste: Weekly_Sales_roll_std_4\n",
            "Criada feature no teste: Weekly_Sales_roll_mean_8\n",
            "Criada feature no teste: Weekly_Sales_roll_median_8\n",
            "Criada feature no teste: Weekly_Sales_roll_sum_8\n",
            "Criada feature no teste: Weekly_Sales_roll_std_8\n",
            "Criada feature no teste: Weekly_Sales_roll_mean_12\n",
            "Criada feature no teste: Weekly_Sales_roll_median_12\n",
            "Criada feature no teste: Weekly_Sales_roll_sum_12\n",
            "Criada feature no teste: Weekly_Sales_roll_std_12\n",
            "Criada feature no teste: Weekly_Sales_roll_mean_26\n",
            "Criada feature no teste: Weekly_Sales_roll_median_26\n",
            "Criada feature no teste: Weekly_Sales_roll_sum_26\n",
            "Criada feature no teste: Weekly_Sales_roll_std_26\n",
            "Criada feature no teste: Weekly_Sales_roll_mean_52\n",
            "Criada feature no teste: Weekly_Sales_roll_median_52\n",
            "Criada feature no teste: Weekly_Sales_roll_sum_52\n",
            "Criada feature no teste: Weekly_Sales_roll_std_52\n",
            "\n",
            "Verificando NaNs no df_train_subset:\n",
            "Weekly_Sales_roll_mean_4       3322\n",
            "Weekly_Sales_roll_median_4     3322\n",
            "Weekly_Sales_roll_sum_4        3322\n",
            "Weekly_Sales_roll_std_4        6609\n",
            "Weekly_Sales_roll_mean_8       3322\n",
            "Weekly_Sales_roll_median_8     3322\n",
            "Weekly_Sales_roll_sum_8        3322\n",
            "Weekly_Sales_roll_std_8        6609\n",
            "Weekly_Sales_roll_mean_12      3322\n",
            "Weekly_Sales_roll_median_12    3322\n",
            "Weekly_Sales_roll_sum_12       3322\n",
            "Weekly_Sales_roll_std_12       6609\n",
            "Weekly_Sales_roll_mean_26      3322\n",
            "Weekly_Sales_roll_median_26    3322\n",
            "Weekly_Sales_roll_sum_26       3322\n",
            "Weekly_Sales_roll_std_26       6609\n",
            "Weekly_Sales_roll_mean_52      3322\n",
            "Weekly_Sales_roll_median_52    3322\n",
            "Weekly_Sales_roll_sum_52       3322\n",
            "Weekly_Sales_roll_std_52       6609\n",
            "dtype: int64\n",
            "\n",
            "Verificando NaNs no df_val_subset:\n",
            "Weekly_Sales_roll_mean_4       26353\n",
            "Weekly_Sales_roll_median_4     26353\n",
            "Weekly_Sales_roll_sum_4        26353\n",
            "Weekly_Sales_roll_std_4        29366\n",
            "Weekly_Sales_roll_mean_8       14414\n",
            "Weekly_Sales_roll_median_8     14414\n",
            "Weekly_Sales_roll_sum_8        14414\n",
            "Weekly_Sales_roll_std_8        17378\n",
            "Weekly_Sales_roll_mean_12       2836\n",
            "Weekly_Sales_roll_median_12     2836\n",
            "Weekly_Sales_roll_sum_12        2836\n",
            "Weekly_Sales_roll_std_12        5687\n",
            "Weekly_Sales_roll_mean_26         22\n",
            "Weekly_Sales_roll_median_26       22\n",
            "Weekly_Sales_roll_sum_26          22\n",
            "Weekly_Sales_roll_std_26          25\n",
            "Weekly_Sales_roll_mean_52         22\n",
            "Weekly_Sales_roll_median_52       22\n",
            "Weekly_Sales_roll_sum_52          22\n",
            "Weekly_Sales_roll_std_52          25\n",
            "dtype: int64\n",
            "\n",
            "Verificando NaNs no df_test:\n",
            "Weekly_Sales_roll_mean_4       102595\n",
            "Weekly_Sales_roll_median_4     102595\n",
            "Weekly_Sales_roll_sum_4        102595\n",
            "Weekly_Sales_roll_std_4        105706\n",
            "Weekly_Sales_roll_mean_8        90422\n",
            "Weekly_Sales_roll_median_8      90422\n",
            "Weekly_Sales_roll_sum_8         90422\n",
            "Weekly_Sales_roll_std_8         93492\n",
            "Weekly_Sales_roll_mean_12       78388\n",
            "Weekly_Sales_roll_median_12     78388\n",
            "Weekly_Sales_roll_sum_12        78388\n",
            "Weekly_Sales_roll_std_12        81430\n",
            "Weekly_Sales_roll_mean_26       36928\n",
            "Weekly_Sales_roll_median_26     36928\n",
            "Weekly_Sales_roll_sum_26        36928\n",
            "Weekly_Sales_roll_std_26        39893\n",
            "Weekly_Sales_roll_mean_52          36\n",
            "Weekly_Sales_roll_median_52        36\n",
            "Weekly_Sales_roll_sum_52           36\n",
            "Weekly_Sales_roll_std_52           78\n",
            "dtype: int64\n",
            "\n",
            "Criação de features de janela móvel concluída!\n"
          ]
        }
      ],
      "source": [
        "# Converter a coluna 'Date' para datetime, se ainda não estiver\n",
        "df_train['Date'] = pd.to_datetime(df_train['Date'])\n",
        "df_test['Date'] = pd.to_datetime(df_test['Date'])\n",
        "\n",
        "# Definir a data de corte para a divisão treino/validação\n",
        "train_end_date = '2012-07-31'\n",
        "val_start_date = '2012-08-01'\n",
        "\n",
        "# Dividir df_train em treino e validação com base na data\n",
        "df_train_subset = df_train[df_train['Date'] <= train_end_date].copy()\n",
        "df_val_subset = df_train[(df_train['Date'] >= val_start_date) & (df_train['Date'] <= '2012-10-26')].copy()\n",
        "\n",
        "print(f\"Treino: {df_train_subset['Date'].min()} a {df_train_subset['Date'].max()} ({len(df_train_subset)} linhas)\")\n",
        "print(f\"Validação: {df_val_subset['Date'].min()} a {df_val_subset['Date'].max()} ({len(df_val_subset)} linhas)\")\n",
        "print(f\"Teste: {df_test['Date'].min()} a {df_test['Date'].max()} ({len(df_test)} linhas)\")\n",
        "\n",
        "# --- Criando Features de Janela Móvel ---\n",
        "window_sizes = [4, 8, 12, 26, 52]\n",
        "stats_to_calculate = ['mean', 'median', 'sum', 'std']\n",
        "\n",
        "# 1. Calcular features para o conjunto de treino\n",
        "df_train_subset = df_train_subset.sort_values(['Store', 'Dept', 'Date'])\n",
        "for window in window_sizes:\n",
        "    for stat in stats_to_calculate:\n",
        "        new_col_name = f'Weekly_Sales_roll_{stat}_{window}'\n",
        "        df_train_subset[new_col_name] = df_train_subset.groupby(['Store', 'Dept'])['Weekly_Sales'].transform(\n",
        "            lambda s: s.rolling(window=window, min_periods=1).agg(stat).shift(1)\n",
        "        )\n",
        "        print(f\"Criada feature no treino: {new_col_name}\")\n",
        "\n",
        "# 2. Calcular features para o conjunto de validação\n",
        "df_val_subset = df_val_subset.sort_values(['Store', 'Dept', 'Date'])\n",
        "for window in window_sizes:\n",
        "    for stat in stats_to_calculate:\n",
        "        new_col_name = f'Weekly_Sales_roll_{stat}_{window}'\n",
        "        # Concatenar dados de treino com validação para garantir continuidade temporal\n",
        "        df_temp = pd.concat([\n",
        "            df_train_subset[['Store', 'Dept', 'Date', 'Weekly_Sales']],\n",
        "            df_val_subset[['Store', 'Dept', 'Date']].assign(Weekly_Sales=np.nan)\n",
        "        ])\n",
        "        df_temp = df_temp.sort_values(['Store', 'Dept', 'Date'])\n",
        "        df_temp[new_col_name] = df_temp.groupby(['Store', 'Dept'])['Weekly_Sales'].transform(\n",
        "            lambda s: s.rolling(window=window, min_periods=1).agg(stat).shift(1)\n",
        "        )\n",
        "        # Atribuir as features ao conjunto de validação\n",
        "        df_val_subset[new_col_name] = df_temp[df_temp['Date'] >= val_start_date][new_col_name].values\n",
        "        print(f\"Criada feature na validação: {new_col_name}\")\n",
        "\n",
        "# 3. Calcular features para o conjunto de teste\n",
        "df_test = df_test.sort_values(['Store', 'Dept', 'Date'])\n",
        "for window in window_sizes:\n",
        "    for stat in stats_to_calculate:\n",
        "        new_col_name = f'Weekly_Sales_roll_{stat}_{window}'\n",
        "        # Concatenar dados de treino com teste para garantir continuidade temporal\n",
        "        df_temp = pd.concat([\n",
        "            df_train[['Store', 'Dept', 'Date', 'Weekly_Sales']],\n",
        "            df_test[['Store', 'Dept', 'Date']].assign(Weekly_Sales=np.nan)\n",
        "        ])\n",
        "        df_temp = df_temp.sort_values(['Store', 'Dept', 'Date'])\n",
        "        df_temp[new_col_name] = df_temp.groupby(['Store', 'Dept'])['Weekly_Sales'].transform(\n",
        "            lambda s: s.rolling(window=window, min_periods=1).agg(stat).shift(1)\n",
        "        )\n",
        "        # Atribuir as features ao conjunto de teste\n",
        "        df_test[new_col_name] = df_temp[df_temp['Date'] >= '2012-11-02'][new_col_name].values\n",
        "        print(f\"Criada feature no teste: {new_col_name}\")\n",
        "\n",
        "# 4. Verificar e tratar NaNs\n",
        "print(\"\\nVerificando NaNs no df_train_subset:\")\n",
        "print(df_train_subset[[col for col in df_train_subset.columns if 'Weekly_Sales_roll_' in col]].isnull().sum())\n",
        "print(\"\\nVerificando NaNs no df_val_subset:\")\n",
        "print(df_val_subset[[col for col in df_val_subset.columns if 'Weekly_Sales_roll_' in col]].isnull().sum())\n",
        "print(\"\\nVerificando NaNs no df_test:\")\n",
        "print(df_test[[col for col in df_test.columns if 'Weekly_Sales_roll_' in col]].isnull().sum())\n",
        "\n",
        "# Tratar NaNs (preencher com a média por grupo)\n",
        "for col in [col for col in df_train_subset.columns if 'Weekly_Sales_roll_' in col]:\n",
        "    df_train_subset[col] = df_train_subset.groupby(['Store', 'Dept'])[col].transform(lambda x: x.fillna(x.mean()))\n",
        "    df_val_subset[col] = df_val_subset.groupby(['Store', 'Dept'])[col].transform(lambda x: x.fillna(x.mean()))\n",
        "    df_test[col] = df_test.groupby(['Store', 'Dept'])[col].transform(lambda x: x.fillna(x.mean()))\n",
        "\n",
        "print(\"\\nCriação de features de janela móvel concluída!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTjelYS8u-Md"
      },
      "source": [
        "## Tratamento Final de NaNs nas Features Criadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjXW6_zrvAzp",
        "outputId": "30338946-65cf-4755-f4cb-2c618a2e2e1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Tratando NaNs Finais nas Features de Janela Móvel e Lag (usando médias do treino para evitar leakage) ---\n",
            "\n",
            "Calculando médias por grupo no conjunto de treino...\n",
            "\n",
            "Tratando NaNs em df_train_subset...\n",
            "\n",
            "Tratando NaNs em df_val_subset...\n",
            "\n",
            "Tratando NaNs em df_test...\n",
            "\n",
            "--- Verificando NaNs em df_train_subset APÓS o tratamento final ---\n",
            "Features de Janela Móvel:\n",
            "Weekly_Sales_roll_mean_4       0\n",
            "Weekly_Sales_roll_median_4     0\n",
            "Weekly_Sales_roll_sum_4        0\n",
            "Weekly_Sales_roll_std_4        0\n",
            "Weekly_Sales_roll_mean_8       0\n",
            "Weekly_Sales_roll_median_8     0\n",
            "Weekly_Sales_roll_sum_8        0\n",
            "Weekly_Sales_roll_std_8        0\n",
            "Weekly_Sales_roll_mean_12      0\n",
            "Weekly_Sales_roll_median_12    0\n",
            "Weekly_Sales_roll_sum_12       0\n",
            "Weekly_Sales_roll_std_12       0\n",
            "Weekly_Sales_roll_mean_26      0\n",
            "Weekly_Sales_roll_median_26    0\n",
            "Weekly_Sales_roll_sum_26       0\n",
            "Weekly_Sales_roll_std_26       0\n",
            "Weekly_Sales_roll_mean_52      0\n",
            "Weekly_Sales_roll_median_52    0\n",
            "Weekly_Sales_roll_sum_52       0\n",
            "Weekly_Sales_roll_std_52       0\n",
            "dtype: int64\n",
            "\n",
            "Features de Lag:\n",
            "Series([], dtype: float64)\n",
            "\n",
            "--- Verificando NaNs em df_val_subset APÓS o tratamento final ---\n",
            "Features de Janela Móvel:\n",
            "Weekly_Sales_roll_mean_4       0\n",
            "Weekly_Sales_roll_median_4     0\n",
            "Weekly_Sales_roll_sum_4        0\n",
            "Weekly_Sales_roll_std_4        0\n",
            "Weekly_Sales_roll_mean_8       0\n",
            "Weekly_Sales_roll_median_8     0\n",
            "Weekly_Sales_roll_sum_8        0\n",
            "Weekly_Sales_roll_std_8        0\n",
            "Weekly_Sales_roll_mean_12      0\n",
            "Weekly_Sales_roll_median_12    0\n",
            "Weekly_Sales_roll_sum_12       0\n",
            "Weekly_Sales_roll_std_12       0\n",
            "Weekly_Sales_roll_mean_26      0\n",
            "Weekly_Sales_roll_median_26    0\n",
            "Weekly_Sales_roll_sum_26       0\n",
            "Weekly_Sales_roll_std_26       0\n",
            "Weekly_Sales_roll_mean_52      0\n",
            "Weekly_Sales_roll_median_52    0\n",
            "Weekly_Sales_roll_sum_52       0\n",
            "Weekly_Sales_roll_std_52       0\n",
            "dtype: int64\n",
            "\n",
            "Features de Lag:\n",
            "Series([], dtype: float64)\n",
            "\n",
            "--- Verificando NaNs em df_test APÓS o tratamento final ---\n",
            "Features de Janela Móvel:\n",
            "Weekly_Sales_roll_mean_4       0\n",
            "Weekly_Sales_roll_median_4     0\n",
            "Weekly_Sales_roll_sum_4        0\n",
            "Weekly_Sales_roll_std_4        0\n",
            "Weekly_Sales_roll_mean_8       0\n",
            "Weekly_Sales_roll_median_8     0\n",
            "Weekly_Sales_roll_sum_8        0\n",
            "Weekly_Sales_roll_std_8        0\n",
            "Weekly_Sales_roll_mean_12      0\n",
            "Weekly_Sales_roll_median_12    0\n",
            "Weekly_Sales_roll_sum_12       0\n",
            "Weekly_Sales_roll_std_12       0\n",
            "Weekly_Sales_roll_mean_26      0\n",
            "Weekly_Sales_roll_median_26    0\n",
            "Weekly_Sales_roll_sum_26       0\n",
            "Weekly_Sales_roll_std_26       0\n",
            "Weekly_Sales_roll_mean_52      0\n",
            "Weekly_Sales_roll_median_52    0\n",
            "Weekly_Sales_roll_sum_52       0\n",
            "Weekly_Sales_roll_std_52       0\n",
            "dtype: int64\n",
            "\n",
            "Features de Lag:\n",
            "Series([], dtype: float64)\n",
            "\n",
            "Tratamento final de NaNs nas features de janela móvel e lag concluído (sem risco de leakage)!\n",
            "\n",
            "--- Preparando Dados para Treinamento ---\n",
            "\n",
            "--- Diagnóstico de Dados Antes do Treinamento ---\n",
            "\n",
            "Tipos de dados em X_treino:\n",
            "IsHoliday                         bool\n",
            "Weekly_Sales_roll_mean_4       float64\n",
            "Weekly_Sales_roll_median_4     float64\n",
            "Weekly_Sales_roll_sum_4        float64\n",
            "Weekly_Sales_roll_std_4        float64\n",
            "Weekly_Sales_roll_mean_8       float64\n",
            "Weekly_Sales_roll_median_8     float64\n",
            "Weekly_Sales_roll_sum_8        float64\n",
            "Weekly_Sales_roll_std_8        float64\n",
            "Weekly_Sales_roll_mean_12      float64\n",
            "Weekly_Sales_roll_median_12    float64\n",
            "Weekly_Sales_roll_sum_12       float64\n",
            "Weekly_Sales_roll_std_12       float64\n",
            "Weekly_Sales_roll_mean_26      float64\n",
            "Weekly_Sales_roll_median_26    float64\n",
            "Weekly_Sales_roll_sum_26       float64\n",
            "Weekly_Sales_roll_std_26       float64\n",
            "Weekly_Sales_roll_mean_52      float64\n",
            "Weekly_Sales_roll_median_52    float64\n",
            "Weekly_Sales_roll_sum_52       float64\n",
            "Weekly_Sales_roll_std_52       float64\n",
            "dtype: object\n",
            "\n",
            "Verificando NaN em X_treino:\n",
            "IsHoliday                      0\n",
            "Weekly_Sales_roll_mean_4       0\n",
            "Weekly_Sales_roll_median_4     0\n",
            "Weekly_Sales_roll_sum_4        0\n",
            "Weekly_Sales_roll_std_4        0\n",
            "Weekly_Sales_roll_mean_8       0\n",
            "Weekly_Sales_roll_median_8     0\n",
            "Weekly_Sales_roll_sum_8        0\n",
            "Weekly_Sales_roll_std_8        0\n",
            "Weekly_Sales_roll_mean_12      0\n",
            "Weekly_Sales_roll_median_12    0\n",
            "Weekly_Sales_roll_sum_12       0\n",
            "Weekly_Sales_roll_std_12       0\n",
            "Weekly_Sales_roll_mean_26      0\n",
            "Weekly_Sales_roll_median_26    0\n",
            "Weekly_Sales_roll_sum_26       0\n",
            "Weekly_Sales_roll_std_26       0\n",
            "Weekly_Sales_roll_mean_52      0\n",
            "Weekly_Sales_roll_median_52    0\n",
            "Weekly_Sales_roll_sum_52       0\n",
            "Weekly_Sales_roll_std_52       0\n",
            "dtype: int64\n",
            "\n",
            "Verificando NaN em y_treino:\n",
            "0\n",
            "\n",
            "Verificando NaN em X_validacao:\n",
            "IsHoliday                      0\n",
            "Weekly_Sales_roll_mean_4       0\n",
            "Weekly_Sales_roll_median_4     0\n",
            "Weekly_Sales_roll_sum_4        0\n",
            "Weekly_Sales_roll_std_4        0\n",
            "Weekly_Sales_roll_mean_8       0\n",
            "Weekly_Sales_roll_median_8     0\n",
            "Weekly_Sales_roll_sum_8        0\n",
            "Weekly_Sales_roll_std_8        0\n",
            "Weekly_Sales_roll_mean_12      0\n",
            "Weekly_Sales_roll_median_12    0\n",
            "Weekly_Sales_roll_sum_12       0\n",
            "Weekly_Sales_roll_std_12       0\n",
            "Weekly_Sales_roll_mean_26      0\n",
            "Weekly_Sales_roll_median_26    0\n",
            "Weekly_Sales_roll_sum_26       0\n",
            "Weekly_Sales_roll_std_26       0\n",
            "Weekly_Sales_roll_mean_52      0\n",
            "Weekly_Sales_roll_median_52    0\n",
            "Weekly_Sales_roll_sum_52       0\n",
            "Weekly_Sales_roll_std_52       0\n",
            "dtype: int64\n",
            "\n",
            "Verificando NaN em y_validacao:\n",
            "0\n",
            "\n",
            "Verificando valores infinitos em X_treino:\n",
            "IsHoliday                      0\n",
            "Weekly_Sales_roll_mean_4       0\n",
            "Weekly_Sales_roll_median_4     0\n",
            "Weekly_Sales_roll_sum_4        0\n",
            "Weekly_Sales_roll_std_4        0\n",
            "Weekly_Sales_roll_mean_8       0\n",
            "Weekly_Sales_roll_median_8     0\n",
            "Weekly_Sales_roll_sum_8        0\n",
            "Weekly_Sales_roll_std_8        0\n",
            "Weekly_Sales_roll_mean_12      0\n",
            "Weekly_Sales_roll_median_12    0\n",
            "Weekly_Sales_roll_sum_12       0\n",
            "Weekly_Sales_roll_std_12       0\n",
            "Weekly_Sales_roll_mean_26      0\n",
            "Weekly_Sales_roll_median_26    0\n",
            "Weekly_Sales_roll_sum_26       0\n",
            "Weekly_Sales_roll_std_26       0\n",
            "Weekly_Sales_roll_mean_52      0\n",
            "Weekly_Sales_roll_median_52    0\n",
            "Weekly_Sales_roll_sum_52       0\n",
            "Weekly_Sales_roll_std_52       0\n",
            "dtype: int64\n",
            "\n",
            "Verificando valores infinitos em y_treino:\n",
            "0\n",
            "\n",
            "Verificando valores infinitos em X_validacao:\n",
            "IsHoliday                      0\n",
            "Weekly_Sales_roll_mean_4       0\n",
            "Weekly_Sales_roll_median_4     0\n",
            "Weekly_Sales_roll_sum_4        0\n",
            "Weekly_Sales_roll_std_4        0\n",
            "Weekly_Sales_roll_mean_8       0\n",
            "Weekly_Sales_roll_median_8     0\n",
            "Weekly_Sales_roll_sum_8        0\n",
            "Weekly_Sales_roll_std_8        0\n",
            "Weekly_Sales_roll_mean_12      0\n",
            "Weekly_Sales_roll_median_12    0\n",
            "Weekly_Sales_roll_sum_12       0\n",
            "Weekly_Sales_roll_std_12       0\n",
            "Weekly_Sales_roll_mean_26      0\n",
            "Weekly_Sales_roll_median_26    0\n",
            "Weekly_Sales_roll_sum_26       0\n",
            "Weekly_Sales_roll_std_26       0\n",
            "Weekly_Sales_roll_mean_52      0\n",
            "Weekly_Sales_roll_median_52    0\n",
            "Weekly_Sales_roll_sum_52       0\n",
            "Weekly_Sales_roll_std_52       0\n",
            "dtype: int64\n",
            "\n",
            "Verificando valores infinitos em y_validacao:\n",
            "0\n",
            "\n",
            "Diagnóstico concluído.\n",
            "\n",
            "--- Iniciando Treinamento e Avaliação de Modelos ---\n",
            "\n",
            "Treinando Modelo: Regressão Linear...\n",
            "Regressão Linear - MAE: 2008.99, RMSE: 4171.76, R²: 0.9639\n",
            "\n",
            "Treinando Modelo: Árvore de Decisão Regressora...\n",
            "Árvore de Decisão - MAE: 3508.04, RMSE: 7767.30, R²: 0.8747\n",
            "\n",
            "Treinando Modelo: Random Forest Regressor...\n",
            "Random Forest - MAE: 2062.52, RMSE: 4445.52, R²: 0.9590\n",
            "\n",
            "Treinando Modelo: Gradient Boosting Regressor...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-35-18c3b34149a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nTreinando Modelo: Gradient Boosting Regressor...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[0mgb_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m \u001b[0mgb_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_treino\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_treino\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;31m# Previsões\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[1;31m# trees use different types for X and y, checking them separately.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0m\u001b[0;32m    413\u001b[0m                                    dtype=DTYPE, multi_output=True)\n\u001b[0;32m    414\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    815\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    614\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    617\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1998\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1999\u001b[0m         if (\n\u001b[1;32m-> 2000\u001b[1;33m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2001\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2002\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_single_block\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Importações necessárias\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# --- Tratando NaNs Finais nas Features de Janela Móvel e Lag (usando médias do treino para evitar leakage) ---\n",
        "print(\"--- Tratando NaNs Finais nas Features de Janela Móvel e Lag (usando médias do treino para evitar leakage) ---\")\n",
        "\n",
        "# Identificar as colunas de janela móvel e lag\n",
        "cols_roll = [col for col in df_train_subset.columns if 'Weekly_Sales_roll_' in col]\n",
        "cols_lag = [col for col in df_train_subset.columns if 'Weekly_Sales_lag_' in col]\n",
        "\n",
        "# Passo 1: Calcular as médias por grupo apenas no conjunto de treino\n",
        "print(\"\\nCalculando médias por grupo no conjunto de treino...\")\n",
        "group_means = {}\n",
        "for col in cols_roll + cols_lag:\n",
        "    means = df_train_subset.groupby(['Store', 'Dept'])[col].mean()\n",
        "    group_means[col] = means\n",
        "\n",
        "# Passo 2: Preencher NaNs em df_train_subset usando as médias do próprio conjunto\n",
        "print(\"\\nTratando NaNs em df_train_subset...\")\n",
        "for col in cols_roll + cols_lag:\n",
        "    df_train_subset[f'{col}_filled'] = df_train_subset.groupby(['Store', 'Dept'])[col].transform(lambda x: x.fillna(x.mean()))\n",
        "    df_train_subset[col] = df_train_subset[f'{col}_filled'].fillna(0)\n",
        "    df_train_subset = df_train_subset.drop(columns=[f'{col}_filled'])\n",
        "\n",
        "# Passo 3: Preencher NaNs em df_val_subset usando as médias do conjunto de treino\n",
        "print(\"\\nTratando NaNs em df_val_subset...\")\n",
        "for col in cols_roll + cols_lag:\n",
        "    df_val_subset[f'{col}_mean'] = df_val_subset.set_index(['Store', 'Dept']).index.map(group_means[col])\n",
        "    df_val_subset[col] = df_val_subset[col].fillna(df_val_subset[f'{col}_mean'])\n",
        "    df_val_subset[col] = df_val_subset[col].fillna(0)\n",
        "    df_val_subset = df_val_subset.drop(columns=[f'{col}_mean'])\n",
        "\n",
        "# Passo 4: Preencher NaNs em df_test usando as médias do conjunto de treino\n",
        "print(\"\\nTratando NaNs em df_test...\")\n",
        "for col in cols_roll + cols_lag:\n",
        "    df_test[f'{col}_mean'] = df_test.set_index(['Store', 'Dept']).index.map(group_means[col])\n",
        "    df_test[col] = df_test[col].fillna(df_test[f'{col}_mean'])\n",
        "    df_test[col] = df_test[col].fillna(0)\n",
        "    df_test = df_test.drop(columns=[f'{col}_mean'])\n",
        "\n",
        "# Verificação final de NaNs\n",
        "print(\"\\n--- Verificando NaNs em df_train_subset APÓS o tratamento final ---\")\n",
        "print(\"Features de Janela Móvel:\")\n",
        "print(df_train_subset[cols_roll].isnull().sum())\n",
        "print(\"\\nFeatures de Lag:\")\n",
        "print(df_train_subset[cols_lag].isnull().sum())\n",
        "\n",
        "print(\"\\n--- Verificando NaNs em df_val_subset APÓS o tratamento final ---\")\n",
        "print(\"Features de Janela Móvel:\")\n",
        "print(df_val_subset[cols_roll].isnull().sum())\n",
        "print(\"\\nFeatures de Lag:\")\n",
        "print(df_val_subset[cols_lag].isnull().sum())\n",
        "\n",
        "print(\"\\n--- Verificando NaNs em df_test APÓS o tratamento final ---\")\n",
        "print(\"Features de Janela Móvel:\")\n",
        "print(df_test[cols_roll].isnull().sum())\n",
        "print(\"\\nFeatures de Lag:\")\n",
        "print(df_test[cols_lag].isnull().sum())\n",
        "\n",
        "print(\"\\nTratamento final de NaNs nas features de janela móvel e lag concluído (sem risco de leakage)!\")\n",
        "\n",
        "# --- Preparação dos Dados para Treinamento ---\n",
        "print(\"\\n--- Preparando Dados para Treinamento ---\")\n",
        "\n",
        "# Definir as features (excluindo Store, Dept, Weekly_Sales e colunas do tipo Timestamp)\n",
        "features = [col for col in df_train_subset.columns \n",
        "            if col not in ['Store', 'Dept', 'Weekly_Sales'] \n",
        "            and not np.issubdtype(df_train_subset[col].dtype, np.datetime64)]\n",
        "\n",
        "X_treino = df_train_subset[features]\n",
        "y_treino = df_train_subset['Weekly_Sales']\n",
        "X_validacao = df_val_subset[features]\n",
        "y_validacao = df_val_subset['Weekly_Sales']\n",
        "\n",
        "# Diagnóstico de Dados Antes do Treinamento\n",
        "print(\"\\n--- Diagnóstico de Dados Antes do Treinamento ---\")\n",
        "print(\"\\nTipos de dados em X_treino:\")\n",
        "print(X_treino.dtypes)\n",
        "print(\"\\nVerificando NaN em X_treino:\")\n",
        "print(X_treino.isnull().sum())\n",
        "print(\"\\nVerificando NaN em y_treino:\")\n",
        "print(y_treino.isnull().sum())\n",
        "print(\"\\nVerificando NaN em X_validacao:\")\n",
        "print(X_validacao.isnull().sum())\n",
        "print(\"\\nVerificando NaN em y_validacao:\")\n",
        "print(y_validacao.isnull().sum())\n",
        "print(\"\\nVerificando valores infinitos em X_treino:\")\n",
        "print(np.isinf(X_treino).sum())\n",
        "print(\"\\nVerificando valores infinitos em y_treino:\")\n",
        "print(np.isinf(y_treino).sum())\n",
        "print(\"\\nVerificando valores infinitos em X_validacao:\")\n",
        "print(np.isinf(X_validacao).sum())\n",
        "print(\"\\nVerificando valores infinitos em y_validacao:\")\n",
        "print(np.isinf(y_validacao).sum())\n",
        "print(\"\\nDiagnóstico concluído.\")\n",
        "\n",
        "# --- Iniciando Treinamento e Avaliação de Modelos ---\n",
        "print(\"\\n--- Iniciando Treinamento e Avaliação de Modelos ---\")\n",
        "\n",
        "# Dicionário para armazenar os resultados dos modelos\n",
        "resultados_modelos = {}\n",
        "\n",
        "# --- Modelo 1: Regressão Linear (Baseline) ---\n",
        "print(\"\\nTreinando Modelo: Regressão Linear...\")\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_treino, y_treino)\n",
        "\n",
        "# Previsões no conjunto de validação\n",
        "y_pred_lr = lr_model.predict(X_validacao)\n",
        "\n",
        "# Avaliação\n",
        "mae_lr = mean_absolute_error(y_validacao, y_pred_lr)\n",
        "rmse_lr = np.sqrt(mean_squared_error(y_validacao, y_pred_lr))\n",
        "r2_lr = r2_score(y_validacao, y_pred_lr)\n",
        "print(f\"Regressão Linear - MAE: {mae_lr:.2f}, RMSE: {rmse_lr:.2f}, R²: {r2_lr:.4f}\")\n",
        "resultados_modelos['Regressão Linear'] = {'MAE': mae_lr, 'RMSE': rmse_lr, 'R2': r2_lr}\n",
        "\n",
        "# --- Modelo 2: Árvore de Decisão Regressora ---\n",
        "print(\"\\nTreinando Modelo: Árvore de Decisão Regressora...\")\n",
        "dt_model = DecisionTreeRegressor(random_state=42)\n",
        "dt_model.fit(X_treino, y_treino)\n",
        "\n",
        "# Previsões\n",
        "y_pred_dt = dt_model.predict(X_validacao)\n",
        "\n",
        "# Avaliação\n",
        "mae_dt = mean_absolute_error(y_validacao, y_pred_dt)\n",
        "rmse_dt = np.sqrt(mean_squared_error(y_validacao, y_pred_dt))\n",
        "r2_dt = r2_score(y_validacao, y_pred_dt)\n",
        "print(f\"Árvore de Decisão - MAE: {mae_dt:.2f}, RMSE: {rmse_dt:.2f}, R²: {r2_dt:.4f}\")\n",
        "resultados_modelos['Árvore de Decisão'] = {'MAE': mae_dt, 'RMSE': rmse_dt, 'R2': r2_dt}\n",
        "\n",
        "# --- Modelo 3: Random Forest Regressor ---\n",
        "print(\"\\nTreinando Modelo: Random Forest Regressor...\")\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, max_depth=20, min_samples_split=5, min_samples_leaf=5)\n",
        "rf_model.fit(X_treino, y_treino)\n",
        "\n",
        "# Previsões\n",
        "y_pred_rf = rf_model.predict(X_validacao)\n",
        "\n",
        "# Avaliação\n",
        "mae_rf = mean_absolute_error(y_validacao, y_pred_rf)\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_validacao, y_pred_rf))\n",
        "r2_rf = r2_score(y_validacao, y_pred_rf)\n",
        "print(f\"Random Forest - MAE: {mae_rf:.2f}, RMSE: {rmse_rf:.2f}, R²: {r2_rf:.4f}\")\n",
        "resultados_modelos['Random Forest'] = {'MAE': mae_rf, 'RMSE': rmse_rf, 'R2': r2_rf}\n",
        "\n",
        "# --- Modelo 4: Gradient Boosting Regressor ---\n",
        "print(\"\\nTreinando Modelo: Gradient Boosting Regressor...\")\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "gb_model.fit(X_treino, y_treino)\n",
        "\n",
        "# Previsões\n",
        "y_pred_gb = gb_model.predict(X_validacao)\n",
        "\n",
        "# Avaliação\n",
        "mae_gb = mean_absolute_error(y_validacao, y_pred_gb)\n",
        "rmse_gb = np.sqrt(mean_squared_error(y_validacao, y_pred_gb))\n",
        "r2_gb = r2_score(y_validacao, y_pred_gb)\n",
        "print(f\"Gradient Boosting - MAE: {mae_gb:.2f}, RMSE: {rmse_gb:.2f}, R²: {r2_gb:.4f}\")\n",
        "resultados_modelos['Gradient Boosting'] = {'MAE': mae_gb, 'RMSE': rmse_gb, 'R2': r2_gb}\n",
        "\n",
        "# --- Resultados Consolidados ---\n",
        "print(\"\\n--- Resultados Consolidados da Avaliação (no conjunto de validação) ---\")\n",
        "df_resultados = pd.DataFrame(resultados_modelos).T\n",
        "print(df_resultados.sort_values(by='RMSE'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTDYAfLy1kqH"
      },
      "source": [
        "# Modelagem e Avaliação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGHIfUc7zofu"
      },
      "source": [
        "## Divisão dos Dados em Conjuntos de Treino e Validação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oisijq9VzpsJ",
        "outputId": "f67ad59e-b08d-4a80-b0f8-b2e9b9c6a67f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Dividindo df_train_merged em Conjuntos de Treino e Validação ---\n",
            "Última data em df_train_merged: 2012-10-26 00:00:00\n",
            "Data de corte para validação (início do conjunto de validação): 2012-07-07 00:00:00\n",
            "\n",
            "Shape do df_train_merged original: (421570, 31)\n",
            "Shape do df_treino_final: (374203, 31)\n",
            "Shape do df_validacao: (47367, 31)\n",
            "\n",
            "Datas em df_treino_final: de 2010-02-05 00:00:00 a 2012-07-06 00:00:00\n",
            "Datas em df_validacao: de 2012-07-13 00:00:00 a 2012-10-26 00:00:00\n",
            "\n",
            "A soma das linhas dos conjuntos de treino final e validação corresponde ao original.\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Dividindo df_train_merged em Conjuntos de Treino e Validação ---\")\n",
        "\n",
        "# 1. Garantir que os dados estão ordenados por data\n",
        "# Isso é crucial para uma divisão cronológica correta.\n",
        "df_train_merged.sort_values(by=['Store', 'Dept', 'Date'], inplace=True)\n",
        "\n",
        "# Identificar a última data no conjunto de treino original\n",
        "ultima_data_treino_completo = df_train_merged['Date'].max()\n",
        "\n",
        "# Definir o período de validação (ex: 16 semanas)\n",
        "periodo_validacao_semanas = 16 # Ajuste conforme necessário (ex: 12, 20, 24 semanas)\n",
        "data_corte = ultima_data_treino_completo - pd.to_timedelta(periodo_validacao_semanas * 7 - 1, unit='D')\n",
        "# Subtraímos (N*7 - 1) dias para que a data de corte seja o início da primeira semana do período de validação\n",
        "\n",
        "print(f\"Última data em df_train_merged: {ultima_data_treino_completo}\")\n",
        "print(f\"Data de corte para validação (início do conjunto de validação): {data_corte}\")\n",
        "\n",
        "# 3. Criar os dataframes de treino final e validação\n",
        "df_treino_final = df_train_merged[df_train_merged['Date'] < data_corte].copy()\n",
        "df_validacao = df_train_merged[df_train_merged['Date'] >= data_corte].copy()\n",
        "\n",
        "# 4. Verificar os resultados da divisão\n",
        "print(f\"\\nShape do df_train_merged original: {df_train_merged.shape}\")\n",
        "print(f\"Shape do df_treino_final: {df_treino_final.shape}\")\n",
        "print(f\"Shape do df_validacao: {df_validacao.shape}\")\n",
        "\n",
        "if not df_treino_final.empty:\n",
        "    print(f\"\\nDatas em df_treino_final: de {df_treino_final['Date'].min()} a {df_treino_final['Date'].max()}\")\n",
        "else:\n",
        "    print(\"\\nATENÇÃO: df_treino_final está vazio! Verifique a data de corte e o período de validação.\")\n",
        "\n",
        "if not df_validacao.empty:\n",
        "    print(f\"Datas em df_validacao: de {df_validacao['Date'].min()} a {df_validacao['Date'].max()}\")\n",
        "else:\n",
        "    print(\"\\nATENÇÃO: df_validacao está vazio! Verifique a data de corte e o período de validação.\")\n",
        "\n",
        "# Verificar se a soma dos dois novos dataframes bate com o original\n",
        "# (pode haver uma pequena diferença se houver NaNs na coluna 'Date' antes da ordenação, o que não deve ser o caso aqui)\n",
        "if df_treino_final.shape[0] + df_validacao.shape[0] == df_train_merged.shape[0]:\n",
        "    print(\"\\nA soma das linhas dos conjuntos de treino final e validação corresponde ao original.\")\n",
        "else:\n",
        "    print(\"\\nATENÇÃO: A soma das linhas dos conjuntos de treino final e validação NÃO corresponde ao original. Verifique a lógica da divisão.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cxBBLxR1ZzL"
      },
      "source": [
        "## Definição das Variáveis (X e y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsOetCNL1Zkh",
        "outputId": "3b3d3ec3-2792-464c-8961-7fc8e061f033"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Shapes das Variáveis Definidas ---\n",
            "Shape de X_treino: (374203, 29)\n",
            "Shape de y_treino: (374203,)\n",
            "Shape de X_validacao: (47367, 29)\n",
            "Shape de y_validacao: (47367,)\n",
            "Shape de X_teste: (115064, 29)\n",
            "\n",
            "--- Colunas em X_treino (exemplo) ---\n",
            "['Store', 'Dept', 'IsHoliday', 'Size', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'Type_A', 'Type_B', 'Type_C', 'Year', 'Month', 'Day', 'WeekOfYear', 'DayOfWeek', 'DayOfYear', 'Weekly_Sales_lag_1', 'Weekly_Sales_lag_2', 'Weekly_Sales_lag_3', 'Weekly_Sales_lag_4', 'Weekly_Sales_lag_12', 'Weekly_Sales_lag_26', 'Weekly_Sales_lag_52']\n",
            "\n",
            "As colunas de features estão consistentes entre os conjuntos de treino, validação e teste.\n"
          ]
        }
      ],
      "source": [
        "# 1. Definir a variável alvo para treino e validação\n",
        "y_treino = df_treino_final['Weekly_Sales']\n",
        "y_validacao = df_validacao['Weekly_Sales']\n",
        "\n",
        "# 2. Definir as colunas de features\n",
        "# Começamos com todas as colunas e depois removemos o alvo e a data original\n",
        "colunas_features = [col for col in df_treino_final.columns if col not in ['Weekly_Sales', 'Date']]\n",
        "\n",
        "X_treino = df_treino_final[colunas_features]\n",
        "X_validacao = df_validacao[colunas_features]\n",
        "X_teste = df_test_merged[colunas_features] # df_test_merged já não tem 'Weekly_Sales'\n",
        "\n",
        "# 3. Verificar os shapes para garantir\n",
        "print(\"--- Shapes das Variáveis Definidas ---\")\n",
        "print(f\"Shape de X_treino: {X_treino.shape}\")\n",
        "print(f\"Shape de y_treino: {y_treino.shape}\")\n",
        "print(f\"Shape de X_validacao: {X_validacao.shape}\")\n",
        "print(f\"Shape de y_validacao: {y_validacao.shape}\")\n",
        "print(f\"Shape de X_teste: {X_teste.shape}\")\n",
        "\n",
        "# 4. Verificar as colunas de X_treino (para confirmar)\n",
        "print(\"\\n--- Colunas em X_treino (exemplo) ---\")\n",
        "print(X_treino.columns.tolist())\n",
        "\n",
        "# 5. Verificar se X_treino, X_validacao e X_teste têm as mesmas colunas na mesma ordem\n",
        "# Isso é importante para os modelos do scikit-learn\n",
        "if list(X_treino.columns) == list(X_validacao.columns) == list(X_teste.columns):\n",
        "    print(\"\\nAs colunas de features estão consistentes entre os conjuntos de treino, validação e teste.\")\n",
        "else:\n",
        "    print(\"\\nATENÇÃO: As colunas de features NÃO estão consistentes entre os conjuntos!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIQJeiX22Mor"
      },
      "source": [
        "#  Treinamento e Avaliação de Modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eom3NXx92RWg"
      },
      "source": [
        "## Modelo de regressão v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABKmt0Fb2Toe",
        "outputId": "89cf5897-46fe-47c3-ec05-740979a2a31d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Iniciando Treinamento e Avaliação de Modelos ---\n",
            "\n",
            "Treinando Modelo: Regressão Linear...\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-33-8655d8d97f49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nTreinando Modelo: Regressão Linear...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mlr_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mlr_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_treino\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_treino\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Previsões no conjunto de validação\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m         X, y = self._validate_data(X, y, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    519\u001b[0m                                    y_numeric=True, multi_output=True)\n\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    815\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    664\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     (type_err,\n",
            "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor # Adicionando para mais opções\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np # Para np.sqrt (para RMSE)\n",
        "\n",
        "print(\"--- Iniciando Treinamento e Avaliação de Modelos ---\")\n",
        "\n",
        "# Dicionário para armazenar os resultados dos modelos\n",
        "resultados_modelos = {}\n",
        "\n",
        "# --- Modelo 1: Regressão Linear (Baseline) ---\n",
        "print(\"\\nTreinando Modelo: Regressão Linear...\")\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_treino, y_treino)\n",
        "\n",
        "# Previsões no conjunto de validação\n",
        "y_pred_lr = lr_model.predict(X_validacao)\n",
        "\n",
        "# Avaliação\n",
        "mae_lr = mean_absolute_error(y_validacao, y_pred_lr)\n",
        "rmse_lr = np.sqrt(mean_squared_error(y_validacao, y_pred_lr))\n",
        "r2_lr = r2_score(y_validacao, y_pred_lr)\n",
        "print(f\"Regressão Linear - MAE: {mae_lr:.2f}, RMSE: {rmse_lr:.2f}, R²: {r2_lr:.4f}\")\n",
        "resultados_modelos['Regressão Linear'] = {'MAE': mae_lr, 'RMSE': rmse_lr, 'R2': r2_lr}\n",
        "\n",
        "# --- Modelo 2: Árvore de Decisão Regressora ---\n",
        "# (Pode ser propensa a overfitting, mas é um bom comparativo)\n",
        "print(\"\\nTreinando Modelo: Árvore de Decisão Regressora...\")\n",
        "# Usar default parameters inicialmente, pode-se ajustar max_depth etc. depois\n",
        "dt_model = DecisionTreeRegressor(random_state=42)\n",
        "dt_model.fit(X_treino, y_treino)\n",
        "\n",
        "# Previsões\n",
        "y_pred_dt = dt_model.predict(X_validacao)\n",
        "\n",
        "# Avaliação\n",
        "mae_dt = mean_absolute_error(y_validacao, y_pred_dt)\n",
        "rmse_dt = np.sqrt(mean_squared_error(y_validacao, y_pred_dt))\n",
        "r2_dt = r2_score(y_validacao, y_pred_dt)\n",
        "print(f\"Árvore de Decisão - MAE: {mae_dt:.2f}, RMSE: {rmse_dt:.2f}, R²: {r2_dt:.4f}\")\n",
        "resultados_modelos['Árvore de Decisão'] = {'MAE': mae_dt, 'RMSE': rmse_dt, 'R2': r2_dt}\n",
        "\n",
        "\n",
        "# --- Modelo 3: Random Forest Regressor ---\n",
        "print(\"\\nTreinando Modelo: Random Forest Regressor...\")\n",
        "# Usar default parameters inicialmente. n_estimators=100 é um bom começo.\n",
        "# random_state para reprodutibilidade. n_jobs=-1 para usar todos os processadores.\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, max_depth=20, min_samples_split=5, min_samples_leaf=5) # Adicionando alguns parâmetros para controle inicial\n",
        "rf_model.fit(X_treino, y_treino)\n",
        "\n",
        "# Previsões\n",
        "y_pred_rf = rf_model.predict(X_validacao)\n",
        "\n",
        "# Avaliação\n",
        "mae_rf = mean_absolute_error(y_validacao, y_pred_rf)\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_validacao, y_pred_rf))\n",
        "r2_rf = r2_score(y_validacao, y_pred_rf)\n",
        "print(f\"Random Forest - MAE: {mae_rf:.2f}, RMSE: {rmse_rf:.2f}, R²: {r2_rf:.4f}\")\n",
        "resultados_modelos['Random Forest'] = {'MAE': mae_rf, 'RMSE': rmse_rf, 'R2': r2_rf}\n",
        "\n",
        "# GradientBoostingRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "print(\"\\nTreinando Modelo: Gradient Boosting Regressor...\")\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "gb_model.fit(X_treino, y_treino)\n",
        "y_pred_gb = gb_model.predict(X_validacao)\n",
        "mae_gb = mean_absolute_error(y_validacao, y_pred_gb)\n",
        "rmse_gb = np.sqrt(mean_squared_error(y_validacao, y_pred_gb))\n",
        "r2_gb = r2_score(y_validacao, y_pred_gb)\n",
        "print(f\"Gradient Boosting - MAE: {mae_gb:.2f}, RMSE: {rmse_gb:.2f}, R²: {r2_gb:.4f}\")\n",
        "resultados_modelos['Gradient Boosting'] = {'MAE': mae_gb, 'RMSE': rmse_gb, 'R2': r2_gb}\n",
        "\n",
        "print(\"\\n--- Resultados Consolidados da Avaliação (no conjunto de validação) ---\")\n",
        "df_resultados = pd.DataFrame(resultados_modelos).T # Transpor para melhor visualização\n",
        "print(df_resultados.sort_values(by='RMSE')) # Ordenar pelo RMSE (menor é melhor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modelo de regressão v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Diagnóstico de Dados Antes do Treinamento ---\n",
            "\n",
            "Verificando NaN em X_treino:\n",
            "Store                       0\n",
            "Dept                        0\n",
            "IsHoliday                   0\n",
            "Size                        0\n",
            "Temperature                 0\n",
            "Fuel_Price                  0\n",
            "MarkDown1                   0\n",
            "MarkDown2                   0\n",
            "MarkDown3                   0\n",
            "MarkDown4                   0\n",
            "MarkDown5                   0\n",
            "CPI                         0\n",
            "Unemployment                0\n",
            "Type_A                      0\n",
            "Type_B                      0\n",
            "Type_C                      0\n",
            "Year                        0\n",
            "Month                       0\n",
            "Day                         0\n",
            "WeekOfYear                  0\n",
            "DayOfWeek                   0\n",
            "DayOfYear                   0\n",
            "Weekly_Sales_lag_1       3318\n",
            "Weekly_Sales_lag_2       6603\n",
            "Weekly_Sales_lag_3       9860\n",
            "Weekly_Sales_lag_4      13099\n",
            "Weekly_Sales_lag_12     38494\n",
            "Weekly_Sales_lag_26     81585\n",
            "Weekly_Sales_lag_52    159641\n",
            "dtype: int64\n",
            "\n",
            "Verificando NaN em y_treino:\n",
            "0\n",
            "\n",
            "Verificando NaN em X_validacao:\n",
            "Store                    0\n",
            "Dept                     0\n",
            "IsHoliday                0\n",
            "Size                     0\n",
            "Temperature              0\n",
            "Fuel_Price               0\n",
            "MarkDown1                0\n",
            "MarkDown2                0\n",
            "MarkDown3                0\n",
            "MarkDown4                0\n",
            "MarkDown5                0\n",
            "CPI                      0\n",
            "Unemployment             0\n",
            "Type_A                   0\n",
            "Type_B                   0\n",
            "Type_C                   0\n",
            "Year                     0\n",
            "Month                    0\n",
            "Day                      0\n",
            "WeekOfYear               0\n",
            "DayOfWeek                0\n",
            "DayOfYear                0\n",
            "Weekly_Sales_lag_1      13\n",
            "Weekly_Sales_lag_2      22\n",
            "Weekly_Sales_lag_3      29\n",
            "Weekly_Sales_lag_4      35\n",
            "Weekly_Sales_lag_12    121\n",
            "Weekly_Sales_lag_26    333\n",
            "Weekly_Sales_lag_52    846\n",
            "dtype: int64\n",
            "\n",
            "Verificando NaN em y_validacao:\n",
            "0\n",
            "\n",
            "Verificando valores infinitos em X_treino:\n",
            "Store                  0\n",
            "Dept                   0\n",
            "IsHoliday              0\n",
            "Size                   0\n",
            "Temperature            0\n",
            "Fuel_Price             0\n",
            "MarkDown1              0\n",
            "MarkDown2              0\n",
            "MarkDown3              0\n",
            "MarkDown4              0\n",
            "MarkDown5              0\n",
            "CPI                    0\n",
            "Unemployment           0\n",
            "Type_A                 0\n",
            "Type_B                 0\n",
            "Type_C                 0\n",
            "Year                   0\n",
            "Month                  0\n",
            "Day                    0\n",
            "WeekOfYear             0\n",
            "DayOfWeek              0\n",
            "DayOfYear              0\n",
            "Weekly_Sales_lag_1     0\n",
            "Weekly_Sales_lag_2     0\n",
            "Weekly_Sales_lag_3     0\n",
            "Weekly_Sales_lag_4     0\n",
            "Weekly_Sales_lag_12    0\n",
            "Weekly_Sales_lag_26    0\n",
            "Weekly_Sales_lag_52    0\n",
            "dtype: int64\n",
            "\n",
            "Verificando valores infinitos em y_treino:\n",
            "0\n",
            "\n",
            "Verificando valores infinitos em X_validacao:\n",
            "Store                  0\n",
            "Dept                   0\n",
            "IsHoliday              0\n",
            "Size                   0\n",
            "Temperature            0\n",
            "Fuel_Price             0\n",
            "MarkDown1              0\n",
            "MarkDown2              0\n",
            "MarkDown3              0\n",
            "MarkDown4              0\n",
            "MarkDown5              0\n",
            "CPI                    0\n",
            "Unemployment           0\n",
            "Type_A                 0\n",
            "Type_B                 0\n",
            "Type_C                 0\n",
            "Year                   0\n",
            "Month                  0\n",
            "Day                    0\n",
            "WeekOfYear             0\n",
            "DayOfWeek              0\n",
            "DayOfYear              0\n",
            "Weekly_Sales_lag_1     0\n",
            "Weekly_Sales_lag_2     0\n",
            "Weekly_Sales_lag_3     0\n",
            "Weekly_Sales_lag_4     0\n",
            "Weekly_Sales_lag_12    0\n",
            "Weekly_Sales_lag_26    0\n",
            "Weekly_Sales_lag_52    0\n",
            "dtype: int64\n",
            "\n",
            "Verificando valores infinitos em y_validacao:\n",
            "0\n",
            "\n",
            "Diagnóstico concluído.\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Diagnóstico de Dados Antes do Treinamento ---\")\n",
        "\n",
        "# Verificar NaN em X_treino e y_treino\n",
        "print(\"\\nVerificando NaN em X_treino:\")\n",
        "print(X_treino.isnull().sum())\n",
        "\n",
        "print(\"\\nVerificando NaN em y_treino:\")\n",
        "print(y_treino.isnull().sum())\n",
        "\n",
        "print(\"\\nVerificando NaN em X_validacao:\")\n",
        "print(X_validacao.isnull().sum())\n",
        "\n",
        "print(\"\\nVerificando NaN em y_validacao:\")\n",
        "print(y_validacao.isnull().sum())\n",
        "\n",
        "# Verificar valores infinitos ou muito grandes\n",
        "print(\"\\nVerificando valores infinitos em X_treino:\")\n",
        "print(np.isinf(X_treino).sum())\n",
        "\n",
        "print(\"\\nVerificando valores infinitos em y_treino:\")\n",
        "print(np.isinf(y_treino).sum())\n",
        "\n",
        "print(\"\\nVerificando valores infinitos em X_validacao:\")\n",
        "print(np.isinf(X_validacao).sum())\n",
        "\n",
        "print(\"\\nVerificando valores infinitos em y_validacao:\")\n",
        "print(np.isinf(y_validacao).sum())\n",
        "\n",
        "print(\"\\nDiagnóstico concluído.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VdIraEgWSsa"
      },
      "source": [
        "## Análise de Importância das Features com Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xDRRc0xSWY-o",
        "outputId": "10bf174e-55f5-4439-c5ef-e948bc693748"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"--- Análise de Importância das Features (Random Forest) ---\")\n",
        "\n",
        "# 1. Extrair a importância das features\n",
        "importances = rf_model.feature_importances_\n",
        "feature_names = X_treino.columns # Lista dos nomes das suas features\n",
        "\n",
        "# 2. Criar um DataFrame para melhor visualização\n",
        "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "\n",
        "# 3. Ordenar as features pela importância (da mais importante para a menos importante)\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 4. Visualizar as features mais importantes\n",
        "print(\"\\nImportância das Features (Top 15):\")\n",
        "display(feature_importance_df.head(15))\n",
        "\n",
        "# Plotar a importância das features (ex: Top 15 ou 20)\n",
        "plt.figure(figsize=(10, 8))\n",
        "top_n_features = 20 # Número de features mais importantes a serem plotadas\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(top_n_features), palette='viridis')\n",
        "plt.title(f'Top {top_n_features} Features Mais Importantes (Random Forest)')\n",
        "plt.xlabel('Importância')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaTHAjgzuQDQ"
      },
      "source": [
        "## Treinamento do Modelo Final (Random Forest) e Previsões no Conjunto de Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXN3Cd5dwPMW",
        "outputId": "d1b9c2dd-5000-4826-e318-0412236f1c57"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "\n",
        "print(\"--- Treinamento do Modelo Final (Random Forest) e Previsões no Teste ---\")\n",
        "\n",
        "# 1. Preparar os dados para o treinamento final\n",
        "# Usaremos todo o df_train_merged para treinar o modelo final.\n",
        "# As 'colunas_features' devem ser as mesmas que você usou para X_treino e X_validacao.\n",
        "# Se você não tem a lista 'colunas_features' disponível nesta célula, recrie-a:\n",
        "if 'colunas_features' not in locals() and 'X_treino' in locals(): # 'locals()' verifica se a variável existe no escopo local\n",
        "    colunas_features = X_treino.columns.tolist()\n",
        "elif 'colunas_features' not in locals():\n",
        "    # Recriar se X_treino também não estiver definido (ajuste se necessário)\n",
        "    colunas_features = [col for col in df_train_merged.columns if col not in ['Weekly_Sales', 'Date']]\n",
        "    print(\"Recriando 'colunas_features'.\")\n",
        "\n",
        "\n",
        "X_full_train = df_train_merged[colunas_features]\n",
        "y_full_train = df_train_merged['Weekly_Sales']\n",
        "\n",
        "# Garantir que X_teste tem as mesmas colunas que X_full_train\n",
        "# (Isso já foi verificado anteriormente, mas é uma boa prática)\n",
        "if list(X_full_train.columns) != list(X_teste.columns):\n",
        "    print(\"ALERTA: Colunas de X_full_train e X_teste não são idênticas! Verifique.\")\n",
        "    # Aqui você poderia adicionar lógica para alinhar colunas, se necessário,\n",
        "    # mas idealmente elas já estão alinhadas pelos passos anteriores.\n",
        "    # X_teste = X_teste[X_full_train.columns] # Exemplo de alinhamento forçado\n",
        "\n",
        "print(f\"Shape de X_full_train: {X_full_train.shape}\")\n",
        "print(f\"Shape de y_full_train: {y_full_train.shape}\")\n",
        "print(f\"Shape de X_teste: {X_teste.shape}\")\n",
        "\n",
        "# 2. Instanciar e Treinar o modelo Random Forest final\n",
        "# Use os parâmetros que você definiu e que deram bons resultados na validação\n",
        "print(\"\\nTreinando o modelo Random Forest final com todos os dados de treino...\")\n",
        "final_rf_model = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    max_depth=20,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=5\n",
        ")\n",
        "final_rf_model.fit(X_full_train, y_full_train)\n",
        "print(\"Treinamento do modelo final concluído.\")\n",
        "\n",
        "# 3. Fazer previsões no conjunto de teste\n",
        "print(\"\\nFazendo previsões no conjunto de teste...\")\n",
        "predicoes_finais_teste = final_rf_model.predict(X_teste)\n",
        "print(\"Previsões no conjunto de teste concluídas.\")\n",
        "print(f\"Número de previsões geradas: {len(predicoes_finais_teste)}\")\n",
        "print(\"Exemplo das primeiras 5 previsões:\", predicoes_finais_teste[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Previsões no teste (Validação do modelo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Permutation Importance "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np # Se não importado antes\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Verifique se as variáveis necessárias existem:\n",
        "if 'rf_model' in locals() and 'X_validacao' in locals() and 'y_validacao' in locals():\n",
        "    print(\"\\n--- Calculando Importância por Permutação ---\")\n",
        "    \n",
        "    # Calcular a importância por permutação\n",
        "    # n_repeats: quantas vezes cada feature é permutada. Mais alto é mais robusto, mas mais lento.\n",
        "    # random_state: para reprodutibilidade\n",
        "    # n_jobs: -1 para usar todos os processadores\n",
        "    perm_importance = permutation_importance(\n",
        "        rf_model, X_validacao, y_validacao, n_repeats=5, random_state=42, n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # Organizar os resultados em um DataFrame\n",
        "    sorted_idx = perm_importance.importances_mean.argsort() # Índices ordenados\n",
        "\n",
        "    perm_importance_df = pd.DataFrame(\n",
        "        perm_importance.importances_mean[sorted_idx].T,\n",
        "        index=X_validacao.columns[sorted_idx], # Nomes das features na ordem correta\n",
        "        columns=['Importance_Permutation']\n",
        "    ).sort_values(by='Importance_Permutation', ascending=False)\n",
        "\n",
        "    print(\"\\nImportância das Features por Permutação (Top 15):\")\n",
        "    display(perm_importance_df.head(15))\n",
        "\n",
        "    # Plotar as features mais importantes\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    perm_importance_df.head(20).plot(kind='barh', legend=False) # Plota as 20 mais importantes\n",
        "    plt.title(\"Top 20 Features Mais Importantes (Importância por Permutação)\")\n",
        "    # A métrica de scoring padrão do regressor é usada (R² para RandomForestRegressor)\n",
        "    # Então o eixo x representa a queda média no R²\n",
        "    plt.xlabel(\"Queda Média na Performance (R²)\") \n",
        "    plt.gca().invert_yaxis() # Para mostrar a feature mais importante no topo\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Variáveis 'rf_model', 'X_validacao' ou 'y_validacao' não estão definidas. Pule a Permutation Importance por enquanto.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Partial Dependence Plots (PDP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Verifique se as variáveis necessárias existem:\n",
        "if 'final_rf_model' in locals() and 'X_full_train' in locals():\n",
        "    # Escolha algumas features para plotar o PDP (ex: as mais importantes do seu modelo)\n",
        "    # Verifique se essas features realmente existem em X_full_train.columns\n",
        "    features_para_pdp = ['Weekly_Sales_lag_1', 'Weekly_Sales_roll_median_4', 'Size', 'DayOfYear', 'Dept'] \n",
        "    \n",
        "    # Filtrar para garantir que apenas features existentes sejam usadas\n",
        "    features_para_pdp_existentes = [f for f in features_para_pdp if f in X_full_train.columns]\n",
        "\n",
        "    if features_para_pdp_existentes:\n",
        "        print(\"\\n--- Gerando Partial Dependence Plots ---\")\n",
        "        \n",
        "        # Determinar o número de linhas e colunas para os subplots\n",
        "        n_features_pdp = len(features_para_pdp_existentes)\n",
        "        n_cols_pdp = 2 # Define 2 colunas de gráficos\n",
        "        n_rows_pdp = (n_features_pdp + n_cols_pdp - 1) // n_cols_pdp # Calcula linhas necessárias\n",
        "        \n",
        "        fig, ax = plt.subplots(n_rows_pdp, n_cols_pdp, figsize=(12, 4 * n_rows_pdp))\n",
        "        ax = ax.flatten() # Transforma ax em um array 1D para fácil iteração\n",
        "\n",
        "        # Gerar PDP para cada feature selecionada\n",
        "        # kind='average' para PDP. 'individual' para ICE plots, 'both' para ambos.\n",
        "        # grid_resolution: número de pontos na grade para calcular a dependência parcial.\n",
        "        # n_jobs: -1 para usar todos os processadores.\n",
        "        display_pdp = PartialDependenceDisplay.from_estimator(\n",
        "            final_rf_model,\n",
        "            X_full_train, # Usa o conjunto de treino para calcular a dependência\n",
        "            features_para_pdp_existentes,\n",
        "            kind='average', \n",
        "            n_jobs=-1,\n",
        "            grid_resolution=20, # Reduza se estiver muito lento, aumente para mais detalhes\n",
        "            ax=ax[:n_features_pdp] # Passa apenas os eixos necessários\n",
        "        )\n",
        "        \n",
        "        # Remover eixos extras se o número de features não preencher todos os subplots\n",
        "        for i in range(n_features_pdp, len(ax)):\n",
        "            fig.delaxes(ax[i])\n",
        "            \n",
        "        plt.suptitle(\"Partial Dependence Plots (PDP) para Features Selecionadas\", fontsize=16, y=1.03) # Ajustar y para não sobrepor\n",
        "        plt.tight_layout(rect=[0, 0, 1, 0.98]) # Ajustar para o supertítulo\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Nenhuma das features selecionadas para PDP foi encontrada em X_full_train.\")\n",
        "else:\n",
        "    print(\"Variáveis 'final_rf_model' ou 'X_full_train' não estão definidas. Pule os PDPs por enquanto.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Avaliar Overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print(\"--- Avaliando Overfitting: Performance no Treino vs. Validação ---\")\n",
        "\n",
        "# Dicionário para armazenar os resultados de treino para comparação\n",
        "resultados_treino = {}\n",
        "# Você já tem 'resultados_modelos' com os dados da VALIDAÇÃO da execução anterior\n",
        "\n",
        "# Função auxiliar para calcular e imprimir métricas\n",
        "def calcular_metricas(nome_modelo, modelo, X, y_real, sufixo_dataset=\"\"):\n",
        "    y_pred = modelo.predict(X)\n",
        "    mae = mean_absolute_error(y_real, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_real, y_pred))\n",
        "    r2 = r2_score(y_real, y_pred)\n",
        "    print(f\"{nome_modelo} - {sufixo_dataset} - MAE: {mae:.2f}, RMSE: {rmse:.2f}, R²: {r2:.4f}\")\n",
        "    return {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
        "\n",
        "# --- Avaliação no Conjunto de Treino ---\n",
        "print(\"\\n--- Performance no Conjunto de Treino ---\")\n",
        "if 'lr_model' in locals():\n",
        "    resultados_treino['Regressão Linear'] = calcular_metricas('Regressão Linear', lr_model, X_treino, y_treino, \"Treino\")\n",
        "if 'dt_model' in locals():\n",
        "    resultados_treino['Árvore de Decisão'] = calcular_metricas('Árvore de Decisão', dt_model, X_treino, y_treino, \"Treino\")\n",
        "if 'rf_model' in locals():\n",
        "    resultados_treino['Random Forest'] = calcular_metricas('Random Forest', rf_model, X_treino, y_treino, \"Treino\")\n",
        "if 'gb_model' in locals():\n",
        "    resultados_treino['Gradient Boosting'] = calcular_metricas('Gradient Boosting', gb_model, X_treino, y_treino, \"Treino\")\n",
        "\n",
        "# --- Relembrar Performance no Conjunto de Validação (você já tem isso em 'resultados_modelos') ---\n",
        "print(\"\\n--- Performance no Conjunto de Validação (Relembrando) ---\")\n",
        "\n",
        "if 'resultados_modelos' in locals() and resultados_modelos:\n",
        "    for nome, metricas_val in resultados_modelos.items():\n",
        "        print(f\"{nome} - Validação - MAE: {metricas_val['MAE']:.2f}, RMSE: {metricas_val['RMSE']:.2f}, R²: {metricas_val['R2']:.4f}\")\n",
        "else:\n",
        "    print(\"Dicionário 'resultados_modelos' com métricas de validação não encontrado. Por favor, execute a avaliação na validação primeiro ou copie os resultados.\")\n",
        "\n",
        "# --- Comparação Direta ---\n",
        "print(\"\\n--- Comparativo Treino vs. Validação ---\")\n",
        "if resultados_treino and 'resultados_modelos' in locals() and resultados_modelos:\n",
        "    df_comp_treino = pd.DataFrame(resultados_treino).T.add_suffix('_Treino')\n",
        "    df_comp_validacao = pd.DataFrame(resultados_modelos).T.add_suffix('_Validação')\n",
        "    \n",
        "    df_comparativo_overfitting = pd.concat([df_comp_treino, df_comp_validacao], axis=1)\n",
        "    # Reordenar para melhor visualização\n",
        "    cols_r2 = [col for col in df_comparativo_overfitting.columns if 'R2' in col]\n",
        "    cols_rmse = [col for col in df_comparativo_overfitting.columns if 'RMSE' in col]\n",
        "    cols_mae = [col for col in df_comparativo_overfitting.columns if 'MAE' in col]\n",
        "    \n",
        "    df_comparativo_overfitting = df_comparativo_overfitting[cols_r2 + cols_rmse + cols_mae]\n",
        "    display(df_comparativo_overfitting)\n",
        "else:\n",
        "    print(\"Não foi possível gerar o comparativo. Verifique se as métricas de treino e validação foram calculadas.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faZgr-wt9jY1"
      },
      "source": [
        "# Gerando arquivo treinado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "e7yB3tkZ9jD2",
        "outputId": "c79b9ceb-4f16-4aba-d849-2324df4a5778"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # Certifique-se de que o pandas está importado\n",
        "\n",
        "print(\"--- Preparando Arquivo de Submissão ---\")\n",
        "\n",
        "# 1. Criar a coluna 'Id' no formato esperado (Store_Dept_Date)\n",
        "# A coluna 'Date' em df_test_merged deve ser do tipo datetime.\n",
        "# Vamos formatá-la como string 'YYYY-MM-DD' para criar o Id.\n",
        "df_test_submission = df_test_merged.copy() # Trabalhar em uma cópia para não alterar o df_test_merged original\n",
        "df_test_submission['Date_str'] = df_test_submission['Date'].dt.strftime('%Y-%m-%d')\n",
        "\n",
        "df_test_submission['Id'] = df_test_submission['Store'].astype(str) + '_' + \\\n",
        "                           df_test_submission['Dept'].astype(str) + '_' + \\\n",
        "                           df_test_submission['Date_str']\n",
        "\n",
        "# 2. Criar o DataFrame de submissão com as colunas 'Id' e 'Weekly_Sales'\n",
        "# A coluna 'Weekly_Sales' aqui conterá suas previsões\n",
        "df_submissao = pd.DataFrame({\n",
        "    'Id': df_test_submission['Id'],\n",
        "    'Weekly_Sales': predicoes_finais_teste  # Suas previsões finais do modelo\n",
        "})\n",
        "\n",
        "# 3. Arredondar as previsões para um número razoável de casas decimais, se desejar\n",
        "# (Muitas competições não exigem, mas pode ser bom para consistência)\n",
        "# df_submissao['Weekly_Sales'] = df_submissao['Weekly_Sales'].round(4)\n",
        "\n",
        "\n",
        "# 4. Salvar o arquivo de submissão com o nome desejado\n",
        "nome_arquivo_submissao = 'random_forest_predictions_walmart.csv'\n",
        "df_submissao.to_csv(nome_arquivo_submissao, index=False)\n",
        "\n",
        "print(f\"\\nArquivo de submissão '{nome_arquivo_submissao}' criado com sucesso.\")\n",
        "\n",
        "# 5. Exibir as primeiras linhas do arquivo de submissão para verificação\n",
        "print(\"\\nExemplo das primeiras 5 linhas do arquivo de submissão:\")\n",
        "display(df_submissao.head())\n",
        "\n",
        "# (Opcional) Verificar o shape do arquivo de submissão\n",
        "print(f\"\\nShape do arquivo de submissão: {df_submissao.shape}\")\n",
        "# Deve corresponder ao número de linhas no sampleSubmission.csv original (115064 linhas, 2 colunas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importando arquivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "p7V2Ov6Z-Smz",
        "outputId": "314a032a-7cc2-4530-d5c1-6f944cc20724"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Nome do arquivo que você quer criar\n",
        "nome_arquivo_submissao = 'random_forest_predictions_walmart.csv'\n",
        "\n",
        "try:\n",
        "    # Salvar o DataFrame como um arquivo CSV\n",
        "    df_submissao.to_csv(nome_arquivo_submissao, index=False)\n",
        "    \n",
        "    print(f\"Arquivo '{nome_arquivo_submissao}' salvo com sucesso no diretório do script!\")\n",
        "    print(\"Você pode encontrá-lo na mesma pasta do seu arquivo .py ou .ipynb.\")\n",
        "      \n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro ao tentar salvar o arquivo CSV: {e}\")\n",
        "    print(\"Verifique se o DataFrame 'df_submissao' existe e está correto.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu3nxWJ0AQaZ"
      },
      "source": [
        "## Incluindo coluna formadata (Vendas em dolars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "18WBDu9-_3Pa",
        "outputId": "46ba3dfc-592b-45a7-822d-8cbec15d3ecb"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# # Criar uma nova coluna formatada para exibição\n",
        "# if 'Weekly_Sales' in df_submissao.columns: # Verifica se a coluna existe\n",
        "#     df_submissao['Weekly_Sales_Formatado'] = df_submissao['Weekly_Sales'].apply(lambda x: f\"${x:,.2f}\")\n",
        "\n",
        "#     print(\"\\nDataFrame de submissão com coluna formatada:\")\n",
        "#     display(df_submissao[['Id', 'Weekly_Sales', 'Weekly_Sales_Formatado']].head())\n",
        "# else:\n",
        "#     print(\"Coluna 'Weekly_Sales' não encontrada no df_submissao para formatação.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMMSR0ntAqXx"
      },
      "source": [
        "# Graficos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XOV_ooSCLuF2",
        "outputId": "06d9380d-8511-437a-cfe5-87a9c430ef85"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- Assumindo que df_validacao (com colunas 'Store', 'Dept', 'Date'),\n",
        "# --- y_validacao (Series Pandas com os valores reais de Weekly_Sales e índice de df_validacao),\n",
        "# --- e y_pred_rf (array NumPy ou Series Pandas com as previsões do Random Forest, alinhado com y_validacao)\n",
        "\n",
        "print(\"--- Gerando Gráficos para Avaliação do Modelo (Random Forest na Validação) ---\")\n",
        "\n",
        "# ==============================================================================\n",
        "# GRÁFICO 1: Valores Reais vs. Previstos (Geral - para todo o conjunto de validação)\n",
        "# Importância para Documentação: Essencial. Mostra a correlação geral e o R².\n",
        "# ==============================================================================\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_validacao, y_pred_rf, alpha=0.3, edgecolors='k', s=20) # Alpha menor para ver densidade\n",
        "plt.plot([min(y_validacao.min(), y_pred_rf.min()), max(y_validacao.max(), y_pred_rf.max())], # Ajustar limites da linha y=x\n",
        "         [min(y_validacao.min(), y_pred_rf.min()), max(y_validacao.max(), y_pred_rf.max())],\n",
        "         'k--', lw=2, label='Previsão Perfeita (y=x)')\n",
        "plt.xlabel(\"Valores Reais (Weekly_Sales)\")\n",
        "plt.ylabel(\"Valores Previstos (Weekly_Sales)\")\n",
        "plt.title(\"Valores Reais vs. Previstos (Random Forest - Validação Geral)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"Este gráfico compara cada venda real no conjunto de validação com a previsão do modelo para ela.\")\n",
        "print(\"Pontos próximos à linha tracejada indicam previsões acuradas.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# GRÁFICO 2: Gráfico de Resíduos (Geral - para todo o conjunto de validação)\n",
        "# Importância para Documentação: Essencial. Ajuda a identificar viés, heterocedasticidade.\n",
        "# ==============================================================================\n",
        "residuos_rf = y_validacao - y_pred_rf\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_pred_rf, residuos_rf, alpha=0.3, edgecolors='k', s=20)\n",
        "plt.hlines(y=0, xmin=y_pred_rf.min(), xmax=y_pred_rf.max(), colors='red', lw=2, linestyles='--')\n",
        "plt.xlabel(\"Valores Previstos (Weekly_Sales)\")\n",
        "plt.ylabel(\"Resíduos (Real - Previsto)\")\n",
        "plt.title(\"Gráfico de Resíduos (Random Forest - Validação Geral)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"Este gráfico mostra os erros de previsão (resíduos) contra os valores previstos.\")\n",
        "print(\"Idealmente, os pontos devem se distribuir aleatoriamente em torno da linha vermelha (erro zero),\")\n",
        "print(\"sem padrões claros, o que indicaria que o modelo não tem viés sistemático.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# GRÁFICO 3: Série Temporal - Vendas Reais vs. Previstas para LOJA 3, DEPARTAMENTO 90\n",
        "# Importância para Documentação: Muito importante. Ilustra o desempenho do modelo\n",
        "# em uma série temporal específica e detalhada.\n",
        "# ==============================================================================\n",
        "loja_especifica = 3\n",
        "depto_especifico = 90\n",
        "\n",
        "# Criar um DataFrame temporário para facilitar a filtragem e o plot\n",
        "df_validacao_plot = df_validacao[['Store', 'Dept', 'Date']].copy()\n",
        "df_validacao_plot['Weekly_Sales_Real'] = y_validacao\n",
        "df_validacao_plot['Weekly_Sales_Prevista_RF'] = y_pred_rf # Supondo alinhamento de índice\n",
        "\n",
        "# Filtrar para a loja e departamento específicos\n",
        "df_validacao_exemplo_especifico = df_validacao_plot[\n",
        "    (df_validacao_plot['Store'] == loja_especifica) &\n",
        "    (df_validacao_plot['Dept'] == depto_especifico)\n",
        "].copy()\n",
        "\n",
        "if not df_validacao_exemplo_especifico.empty:\n",
        "    df_validacao_exemplo_especifico.sort_values('Date', inplace=True)\n",
        "\n",
        "    plt.figure(figsize=(14, 7)) # Tamanho maior para melhor visualização da série temporal\n",
        "    plt.plot(df_validacao_exemplo_especifico['Date'], df_validacao_exemplo_especifico['Weekly_Sales_Real'], label='Vendas Reais', marker='o', linestyle='-', linewidth=1.5)\n",
        "    plt.plot(df_validacao_exemplo_especifico['Date'], df_validacao_exemplo_especifico['Weekly_Sales_Prevista_RF'], label='Vendas Previstas (RF)', marker='x', linestyle='--', linewidth=1.5)\n",
        "    plt.xlabel(\"Data\")\n",
        "    plt.ylabel(\"Weekly_Sales\")\n",
        "    plt.title(f\"Vendas Reais vs. Previstas para Loja {loja_especifica}, Depto {depto_especifico} (Validação)\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(f\"Este gráfico mostra o comportamento das vendas reais e previstas ao longo do tempo para a Loja {loja_especifica}, Depto {depto_especifico}.\")\n",
        "    print(\"Permite analisar se o modelo captura tendências, sazonalidades e picos para esta combinação específica.\")\n",
        "\n",
        "else:\n",
        "    print(f\"ATENÇÃO: Não foram encontrados dados para Loja {loja_especifica}, Depto {depto_especifico} no conjunto de validação.\")\n",
        "    print(\"Verifique se essa combinação de loja/depto existe no seu 'df_validacao'.\")\n",
        "    print(\"Você pode listar as combinações únicas com: df_validacao[['Store', 'Dept']].drop_duplicates().sort_values(by=['Store', 'Dept'])\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# GRÁFICO 4: Histograma dos Resíduos (Geral - para todo o conjunto de validação)\n",
        "# Importância para Documentação: Importante. Mostra a distribuição dos erros.\n",
        "# ==============================================================================\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(residuos_rf, kde=True, bins=50) # kde=True adiciona uma estimativa de densidade do kernel\n",
        "plt.xlabel(\"Resíduos (Real - Previsto)\")\n",
        "plt.ylabel(\"Frequência\")\n",
        "plt.title(\"Histograma dos Resíduos (Random Forest - Validação Geral)\")\n",
        "plt.axvline(residuos_rf.mean(), color='red', linestyle='dashed', linewidth=1, label=f'Média dos Resíduos: {residuos_rf.mean():.2f}')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"Este gráfico mostra a distribuição dos erros de previsão.\")\n",
        "print(\"Idealmente, a distribuição seria centrada em zero e aproximadamente simétrica,\")\n",
        "print(\"indicando que os erros não são sistematicamente para mais ou para menos.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# GRÁFICO 5 (Já gerado antes, mas essencial para a documentação): Importância das Features\n",
        "# Importância para Documentação: Essencial. Explica quais fatores mais influenciam as previsões.\n",
        "# ==============================================================================\n",
        "\n",
        "if 'rf_model' in locals() and 'X_treino' in locals(): # Verifica se as variáveis existem\n",
        "    importances = rf_model.feature_importances_\n",
        "    feature_names = X_treino.columns\n",
        "    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    top_n_features = 20\n",
        "    sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(top_n_features), palette='viridis')\n",
        "    plt.title(f'Top {top_n_features} Features Mais Importantes (Random Forest)')\n",
        "    plt.xlabel('Importância')\n",
        "    plt.ylabel('Feature')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(\"Este gráfico mostra quais features o modelo considerou mais importantes para fazer as previsões.\")\n",
        "else:\n",
        "    print(\"\\nModelo 'rf_model' ou 'X_treino' não definidos. Pule o gráfico de importância das features ou gere-o na célula apropriada.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
